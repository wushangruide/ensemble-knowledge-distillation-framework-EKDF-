{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa9a740c-0047-48cc-a459-ba62daa0a937",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight:  None\n",
      "lr:  0.01\n",
      "n_epoch:  30\n",
      "batch_size:  64\n",
      "n_gen:  3\n",
      "dataset:  cifar10\n",
      "outdir:  ./snapshots\n",
      "print_interval:  50\n",
      "Files already downloaded and verified\n",
      "train...\n",
      "epoch: 0, iter: 50, train_loss: 2.99985125541687, val_loss: 2.3925644394698415\n",
      "epoch: 0, iter: 100, train_loss: 2.299298114776611, val_loss: 2.132373481799083\n",
      "epoch: 0, iter: 150, train_loss: 2.0798945450782775, val_loss: 2.0386597168673375\n",
      "epoch: 0, iter: 200, train_loss: 1.9813673377037049, val_loss: 1.9375261068344116\n",
      "epoch: 0, iter: 250, train_loss: 1.9276276683807374, val_loss: 1.866250036628383\n",
      "epoch: 0, iter: 300, train_loss: 1.8674716901779176, val_loss: 1.9111368041129628\n",
      "epoch: 0, iter: 350, train_loss: 1.8574968981742859, val_loss: 1.7868014384227193\n",
      "epoch: 0, iter: 400, train_loss: 1.7875313544273377, val_loss: 1.7574727148007436\n",
      "epoch: 0, iter: 450, train_loss: 1.7844722747802735, val_loss: 1.6952189419679582\n",
      "epoch: 0, iter: 500, train_loss: 1.7273043918609619, val_loss: 1.6567081509122423\n",
      "epoch: 0, iter: 550, train_loss: 1.6899957799911498, val_loss: 1.6312337665800836\n",
      "epoch: 0, iter: 600, train_loss: 1.6543731021881103, val_loss: 1.6146301182971639\n",
      "epoch: 0, iter: 650, train_loss: 1.6038504648208618, val_loss: 1.6116570834141628\n",
      "epoch: 0, iter: 700, train_loss: 1.5976948595046998, val_loss: 1.5376244001327806\n",
      "epoch: 0, iter: 750, train_loss: 1.5901220846176147, val_loss: 1.5275474672864198\n",
      "epoch: 1, iter: 800, train_loss: 0.54504399061203, val_loss: 1.5235778518543122\n",
      "epoch: 1, iter: 850, train_loss: 1.5143097782135009, val_loss: 1.4775283564427855\n",
      "epoch: 1, iter: 900, train_loss: 1.460588939189911, val_loss: 1.4612625860104895\n",
      "epoch: 1, iter: 950, train_loss: 1.4658956003189088, val_loss: 1.3936975108590095\n",
      "epoch: 1, iter: 1000, train_loss: 1.3592864608764648, val_loss: 1.374500401460441\n",
      "epoch: 1, iter: 1050, train_loss: 1.3626173734664917, val_loss: 1.3718859078777823\n",
      "epoch: 1, iter: 1100, train_loss: 1.3934763550758362, val_loss: 1.340467648900998\n",
      "epoch: 1, iter: 1150, train_loss: 1.2638167428970337, val_loss: 1.274052380756208\n",
      "epoch: 1, iter: 1200, train_loss: 1.2567497754096986, val_loss: 1.2226153080630455\n",
      "epoch: 1, iter: 1250, train_loss: 1.2201778852939607, val_loss: 1.2428964623220407\n",
      "epoch: 1, iter: 1300, train_loss: 1.2198524284362793, val_loss: 1.2056890676735312\n",
      "epoch: 1, iter: 1350, train_loss: 1.190724595785141, val_loss: 1.1412686424650205\n",
      "epoch: 1, iter: 1400, train_loss: 1.1332775461673736, val_loss: 1.1043455726022173\n",
      "epoch: 1, iter: 1450, train_loss: 1.1163477063179017, val_loss: 1.0832207252265542\n",
      "epoch: 1, iter: 1500, train_loss: 1.064528958797455, val_loss: 1.0913954475882706\n",
      "epoch: 1, iter: 1550, train_loss: 1.0929230916500092, val_loss: 1.0498141760279418\n",
      "epoch: 2, iter: 1600, train_loss: 0.754682981967926, val_loss: 1.0776080701761186\n",
      "epoch: 2, iter: 1650, train_loss: 1.0164319610595702, val_loss: 1.0641933637819472\n",
      "epoch: 2, iter: 1700, train_loss: 1.0206106233596801, val_loss: 1.0038747244579778\n",
      "epoch: 2, iter: 1750, train_loss: 0.9832339668273926, val_loss: 0.9960380492696337\n",
      "epoch: 2, iter: 1800, train_loss: 0.9581879603862763, val_loss: 0.9850656728076327\n",
      "epoch: 2, iter: 1850, train_loss: 0.9680313396453858, val_loss: 0.9670291861910729\n",
      "epoch: 2, iter: 1900, train_loss: 0.9029215836524963, val_loss: 0.9399937410263499\n",
      "epoch: 2, iter: 1950, train_loss: 0.9120262968540191, val_loss: 0.8870137368038202\n",
      "epoch: 2, iter: 2000, train_loss: 0.9204327464103699, val_loss: 0.9145214371620469\n",
      "epoch: 2, iter: 2050, train_loss: 0.8953013181686401, val_loss: 0.87782706842301\n",
      "epoch: 2, iter: 2100, train_loss: 0.8738661599159241, val_loss: 0.8833260008483935\n",
      "epoch: 2, iter: 2150, train_loss: 0.8574878060817719, val_loss: 0.8740290057886938\n",
      "epoch: 2, iter: 2200, train_loss: 0.8397945201396942, val_loss: 0.8463675842922964\n",
      "epoch: 2, iter: 2250, train_loss: 0.8158707582950592, val_loss: 0.8243901501795289\n",
      "epoch: 2, iter: 2300, train_loss: 0.8009926772117615, val_loss: 0.8285057601655365\n",
      "epoch: 3, iter: 2350, train_loss: 0.0675580894947052, val_loss: 0.842246095086359\n",
      "epoch: 3, iter: 2400, train_loss: 0.7525745546817779, val_loss: 0.8036880284357982\n",
      "epoch: 3, iter: 2450, train_loss: 0.7316410398483276, val_loss: 0.7792698087965607\n",
      "epoch: 3, iter: 2500, train_loss: 0.7031352227926254, val_loss: 0.7976837105052487\n",
      "epoch: 3, iter: 2550, train_loss: 0.7094970184564591, val_loss: 0.7950907178745148\n",
      "epoch: 3, iter: 2600, train_loss: 0.7079066205024719, val_loss: 0.75627660865237\n",
      "epoch: 3, iter: 2650, train_loss: 0.6819089841842652, val_loss: 0.7416478820667145\n",
      "epoch: 3, iter: 2700, train_loss: 0.7305634140968322, val_loss: 0.7505413821548413\n",
      "epoch: 3, iter: 2750, train_loss: 0.6748531514406204, val_loss: 0.7223458493211466\n",
      "epoch: 3, iter: 2800, train_loss: 0.6763894551992417, val_loss: 0.7360186728702229\n",
      "epoch: 3, iter: 2850, train_loss: 0.6685369551181793, val_loss: 0.7154356738564315\n",
      "epoch: 3, iter: 2900, train_loss: 0.6463978576660157, val_loss: 0.7087231331570133\n",
      "epoch: 3, iter: 2950, train_loss: 0.6826799213886261, val_loss: 0.6929897914646538\n",
      "epoch: 3, iter: 3000, train_loss: 0.6568600189685821, val_loss: 0.6965221257726099\n",
      "epoch: 3, iter: 3050, train_loss: 0.6494605922698975, val_loss: 0.654879610060127\n",
      "epoch: 3, iter: 3100, train_loss: 0.6498111236095429, val_loss: 0.6544066817517493\n",
      "epoch: 4, iter: 3150, train_loss: 0.22473520934581756, val_loss: 0.6632305256500366\n",
      "epoch: 4, iter: 3200, train_loss: 0.5090357112884522, val_loss: 0.6626930944858842\n",
      "epoch: 4, iter: 3250, train_loss: 0.5516896080970765, val_loss: 0.7001106634641149\n",
      "epoch: 4, iter: 3300, train_loss: 0.5287794759869575, val_loss: 0.6560888444162478\n",
      "epoch: 4, iter: 3350, train_loss: 0.5503423333168029, val_loss: 0.6337548314006465\n",
      "epoch: 4, iter: 3400, train_loss: 0.5578365671634674, val_loss: 0.634950627187255\n",
      "epoch: 4, iter: 3450, train_loss: 0.5372235137224197, val_loss: 0.6579517632912678\n",
      "epoch: 4, iter: 3500, train_loss: 0.507999234199524, val_loss: 0.6945513739327717\n",
      "epoch: 4, iter: 3550, train_loss: 0.5443835812807083, val_loss: 0.6387987332359241\n",
      "epoch: 4, iter: 3600, train_loss: 0.5090491199493408, val_loss: 0.6307376289063957\n",
      "epoch: 4, iter: 3650, train_loss: 0.540639967918396, val_loss: 0.6170603547506271\n",
      "epoch: 4, iter: 3700, train_loss: 0.5405141717195511, val_loss: 0.6020859514072443\n",
      "epoch: 4, iter: 3750, train_loss: 0.5130782514810562, val_loss: 0.5870656137633475\n",
      "epoch: 4, iter: 3800, train_loss: 0.5023737442493439, val_loss: 0.5776776077261396\n",
      "epoch: 4, iter: 3850, train_loss: 0.5186228042840958, val_loss: 0.5833930434884539\n",
      "epoch: 4, iter: 3900, train_loss: 0.5034250330924988, val_loss: 0.5942443941429163\n",
      "epoch: 5, iter: 3950, train_loss: 0.31277152061462404, val_loss: 0.5780458132362669\n",
      "epoch: 5, iter: 4000, train_loss: 0.3719092732667923, val_loss: 0.5697655710065441\n",
      "epoch: 5, iter: 4050, train_loss: 0.3688397455215454, val_loss: 0.5980430637385435\n",
      "epoch: 5, iter: 4100, train_loss: 0.4305268993973732, val_loss: 0.5879132749548384\n",
      "epoch: 5, iter: 4150, train_loss: 0.4047588896751404, val_loss: 0.5684212855282863\n",
      "epoch: 5, iter: 4200, train_loss: 0.3807071360945702, val_loss: 0.6008904003033972\n",
      "epoch: 5, iter: 4250, train_loss: 0.4383902966976166, val_loss: 0.5967680428438126\n",
      "epoch: 5, iter: 4300, train_loss: 0.41162255495786665, val_loss: 0.569760587659611\n",
      "epoch: 5, iter: 4350, train_loss: 0.40420107781887055, val_loss: 0.5565710215811517\n",
      "epoch: 5, iter: 4400, train_loss: 0.4197268480062485, val_loss: 0.5670868517107265\n",
      "epoch: 5, iter: 4450, train_loss: 0.4203637447953224, val_loss: 0.5683358328737271\n",
      "epoch: 5, iter: 4500, train_loss: 0.42531424582004546, val_loss: 0.5793269082998774\n",
      "epoch: 5, iter: 4550, train_loss: 0.4004318219423294, val_loss: 0.5577927660790218\n",
      "epoch: 5, iter: 4600, train_loss: 0.41519251465797424, val_loss: 0.5803235635446136\n",
      "epoch: 5, iter: 4650, train_loss: 0.3782468247413635, val_loss: 0.5664656633024763\n",
      "epoch: 6, iter: 4700, train_loss: 0.05169844925403595, val_loss: 0.6185230982911055\n",
      "epoch: 6, iter: 4750, train_loss: 0.2647365342080593, val_loss: 0.5619545969044327\n",
      "epoch: 6, iter: 4800, train_loss: 0.2697502914071083, val_loss: 0.5865380694721914\n",
      "epoch: 6, iter: 4850, train_loss: 0.27280264392495157, val_loss: 0.568042477509778\n",
      "epoch: 6, iter: 4900, train_loss: 0.29940567433834075, val_loss: 0.6188184436719129\n",
      "epoch: 6, iter: 4950, train_loss: 0.30774172842502595, val_loss: 0.5986553388796035\n",
      "epoch: 6, iter: 5000, train_loss: 0.3008857277035713, val_loss: 0.5661160026196461\n",
      "epoch: 6, iter: 5050, train_loss: 0.320029553771019, val_loss: 0.5683335227191828\n",
      "epoch: 6, iter: 5100, train_loss: 0.2949983301758766, val_loss: 0.606636231112632\n",
      "epoch: 6, iter: 5150, train_loss: 0.31141666650772093, val_loss: 0.5708361051644489\n",
      "epoch: 6, iter: 5200, train_loss: 0.30584261476993563, val_loss: 0.5871223746591313\n",
      "epoch: 6, iter: 5250, train_loss: 0.3260092969238758, val_loss: 0.5858260283044948\n",
      "epoch: 6, iter: 5300, train_loss: 0.35579790830612185, val_loss: 0.5559242087754475\n",
      "epoch: 6, iter: 5350, train_loss: 0.32874660551548, val_loss: 0.5481929880608419\n",
      "epoch: 6, iter: 5400, train_loss: 0.3239359802007675, val_loss: 0.5653196213541517\n",
      "epoch: 6, iter: 5450, train_loss: 0.3112804415822029, val_loss: 0.5647275464929593\n",
      "epoch: 7, iter: 5500, train_loss: 0.103441421687603, val_loss: 0.5746651758813555\n",
      "epoch: 7, iter: 5550, train_loss: 0.16391520284116268, val_loss: 0.5718966930345365\n",
      "epoch: 7, iter: 5600, train_loss: 0.18668224394321442, val_loss: 0.6315184793654521\n",
      "epoch: 7, iter: 5650, train_loss: 0.20310028791427612, val_loss: 0.5829695972857202\n",
      "epoch: 7, iter: 5700, train_loss: 0.20750811740756034, val_loss: 0.6457330731639437\n",
      "epoch: 7, iter: 5750, train_loss: 0.20743116438388826, val_loss: 0.5910246369375545\n",
      "epoch: 7, iter: 5800, train_loss: 0.2178518369793892, val_loss: 0.6077871584588554\n",
      "epoch: 7, iter: 5850, train_loss: 0.22225433394312857, val_loss: 0.6043224454305733\n",
      "epoch: 7, iter: 5900, train_loss: 0.2369675835967064, val_loss: 0.6086408269063682\n",
      "epoch: 7, iter: 5950, train_loss: 0.21907794639468192, val_loss: 0.5960003010406616\n",
      "epoch: 7, iter: 6000, train_loss: 0.23049819827079773, val_loss: 0.587788952004378\n",
      "epoch: 7, iter: 6050, train_loss: 0.22311491698026656, val_loss: 0.5761662890577013\n",
      "epoch: 7, iter: 6100, train_loss: 0.2628687362372875, val_loss: 0.553104695051339\n",
      "epoch: 7, iter: 6150, train_loss: 0.22441389679908752, val_loss: 0.5907192874676103\n",
      "epoch: 7, iter: 6200, train_loss: 0.20160042896866798, val_loss: 0.5675188017309092\n",
      "epoch: 7, iter: 6250, train_loss: 0.25042445078492165, val_loss: 0.5870700673123074\n",
      "epoch: 8, iter: 6300, train_loss: 0.11838594987988472, val_loss: 0.6160709184066505\n",
      "epoch: 8, iter: 6350, train_loss: 0.1117738749831915, val_loss: 0.5988274217601035\n",
      "epoch: 8, iter: 6400, train_loss: 0.12100499302148819, val_loss: 0.5911681887450492\n",
      "epoch: 8, iter: 6450, train_loss: 0.1198621741682291, val_loss: 0.6272722590880789\n",
      "epoch: 8, iter: 6500, train_loss: 0.14347348511219024, val_loss: 0.6469967703151095\n",
      "epoch: 8, iter: 6550, train_loss: 0.14546119678765534, val_loss: 0.6425903705749542\n",
      "epoch: 8, iter: 6600, train_loss: 0.1518963621556759, val_loss: 0.6531179702965317\n",
      "epoch: 8, iter: 6650, train_loss: 0.14132720679044725, val_loss: 0.652382572745062\n",
      "epoch: 8, iter: 6700, train_loss: 0.17415485255420207, val_loss: 0.6323683605452252\n",
      "epoch: 8, iter: 6750, train_loss: 0.15621143884956837, val_loss: 0.6313721497727048\n",
      "epoch: 8, iter: 6800, train_loss: 0.15360088273882866, val_loss: 0.6551605148869715\n",
      "epoch: 8, iter: 6850, train_loss: 0.159464373216033, val_loss: 0.6291540494770002\n",
      "epoch: 8, iter: 6900, train_loss: 0.19526011526584625, val_loss: 0.6199070052925948\n",
      "epoch: 8, iter: 6950, train_loss: 0.20386780984699726, val_loss: 0.638856690970196\n",
      "epoch: 8, iter: 7000, train_loss: 0.17235407769680022, val_loss: 0.6132389889780883\n",
      "epoch: 9, iter: 7050, train_loss: 0.021968475580215453, val_loss: 0.679311845712601\n",
      "epoch: 9, iter: 7100, train_loss: 0.09643229108303786, val_loss: 0.6272464977328185\n",
      "epoch: 9, iter: 7150, train_loss: 0.09085725665092469, val_loss: 0.6834868130980024\n",
      "epoch: 9, iter: 7200, train_loss: 0.09956182494759559, val_loss: 0.6584703430628321\n",
      "epoch: 9, iter: 7250, train_loss: 0.09000743322074413, val_loss: 0.6379516793379358\n",
      "epoch: 9, iter: 7300, train_loss: 0.09101903372444213, val_loss: 0.6669015324419472\n",
      "epoch: 9, iter: 7350, train_loss: 0.08933967240154743, val_loss: 0.694861264934965\n",
      "epoch: 9, iter: 7400, train_loss: 0.12164538539946079, val_loss: 0.6974452480578878\n",
      "epoch: 9, iter: 7450, train_loss: 0.11173481129109859, val_loss: 0.6517097026489342\n",
      "epoch: 9, iter: 7500, train_loss: 0.10567787896841764, val_loss: 0.6597165464405801\n",
      "epoch: 9, iter: 7550, train_loss: 0.11071433618664742, val_loss: 0.7230241887129036\n",
      "epoch: 9, iter: 7600, train_loss: 0.1300940121151507, val_loss: 0.6887036572406247\n",
      "epoch: 9, iter: 7650, train_loss: 0.15933992821723222, val_loss: 0.6710738549186925\n",
      "epoch: 9, iter: 7700, train_loss: 0.13050742000341414, val_loss: 0.6601241013616513\n",
      "epoch: 9, iter: 7750, train_loss: 0.13495140410959722, val_loss: 0.632502836121875\n",
      "epoch: 9, iter: 7800, train_loss: 0.12330599784851075, val_loss: 0.6526410650865287\n",
      "epoch: 10, iter: 7850, train_loss: 0.06212160088121891, val_loss: 0.6935577462812897\n",
      "epoch: 10, iter: 7900, train_loss: 0.08139589888975024, val_loss: 0.6590771548877097\n",
      "epoch: 10, iter: 7950, train_loss: 0.0863367484509945, val_loss: 0.7287088522485866\n",
      "epoch: 10, iter: 8000, train_loss: 0.08722123969346285, val_loss: 0.6934769174475579\n",
      "epoch: 10, iter: 8050, train_loss: 0.08802631508558989, val_loss: 0.7444747095085253\n",
      "epoch: 10, iter: 8100, train_loss: 0.0790328114386648, val_loss: 0.7222506130576893\n",
      "epoch: 10, iter: 8150, train_loss: 0.07697884952649474, val_loss: 0.6882968261173577\n",
      "epoch: 10, iter: 8200, train_loss: 0.08251339305192232, val_loss: 0.7230142508722415\n",
      "epoch: 10, iter: 8250, train_loss: 0.08513418052345514, val_loss: 0.7667394235825084\n",
      "epoch: 10, iter: 8300, train_loss: 0.09043071109801532, val_loss: 0.727548470542689\n",
      "epoch: 10, iter: 8350, train_loss: 0.10607398021966219, val_loss: 0.7160269383602081\n",
      "epoch: 10, iter: 8400, train_loss: 0.09927267502993345, val_loss: 0.7204981966383138\n",
      "epoch: 10, iter: 8450, train_loss: 0.12094846557825804, val_loss: 0.7347606424313442\n",
      "epoch: 10, iter: 8500, train_loss: 0.12210954032838345, val_loss: 0.7020802410544863\n",
      "epoch: 10, iter: 8550, train_loss: 0.12809016846120358, val_loss: 0.7060380475536273\n",
      "epoch: 10, iter: 8600, train_loss: 0.1278137432038784, val_loss: 0.7027917213880333\n",
      "epoch: 11, iter: 8650, train_loss: 0.07388657232746482, val_loss: 0.698803377189454\n",
      "epoch: 11, iter: 8700, train_loss: 0.05699824957177043, val_loss: 0.7408294645464344\n",
      "epoch: 11, iter: 8750, train_loss: 0.06639868261292577, val_loss: 0.7136289905400792\n",
      "epoch: 11, iter: 8800, train_loss: 0.06095625601708889, val_loss: 0.7424298145209148\n",
      "epoch: 11, iter: 8850, train_loss: 0.043495291601866486, val_loss: 0.7464982958356287\n",
      "epoch: 11, iter: 8900, train_loss: 0.059071339387446645, val_loss: 0.7347069007765715\n",
      "epoch: 11, iter: 8950, train_loss: 0.06921483468264342, val_loss: 0.766314799049098\n",
      "epoch: 11, iter: 9000, train_loss: 0.08614051315933466, val_loss: 0.7593890407662482\n",
      "epoch: 11, iter: 9050, train_loss: 0.08036275118589402, val_loss: 0.7699101114538824\n",
      "epoch: 11, iter: 9100, train_loss: 0.08001373132690787, val_loss: 0.7354452727706569\n",
      "epoch: 11, iter: 9150, train_loss: 0.071141323056072, val_loss: 0.7639139843214849\n",
      "epoch: 11, iter: 9200, train_loss: 0.0885934491455555, val_loss: 0.7616854811170298\n",
      "epoch: 11, iter: 9250, train_loss: 0.09634700745344162, val_loss: 0.7722826542178537\n",
      "epoch: 11, iter: 9300, train_loss: 0.09652933903969824, val_loss: 0.7603718010103626\n",
      "epoch: 11, iter: 9350, train_loss: 0.08648957014083862, val_loss: 0.7676640772705625\n",
      "epoch: 12, iter: 9400, train_loss: 0.021541969478130342, val_loss: 0.7836072177264342\n",
      "epoch: 12, iter: 9450, train_loss: 0.05158275021240115, val_loss: 0.7575018035758073\n",
      "epoch: 12, iter: 9500, train_loss: 0.04898132348433137, val_loss: 0.8119217442099456\n",
      "epoch: 12, iter: 9550, train_loss: 0.0640795211866498, val_loss: 0.7870794026904805\n",
      "epoch: 12, iter: 9600, train_loss: 0.04886385653167963, val_loss: 0.7879091470864168\n",
      "epoch: 12, iter: 9650, train_loss: 0.054835638627409936, val_loss: 0.8099428492177064\n",
      "epoch: 12, iter: 9700, train_loss: 0.06534121570177376, val_loss: 0.7778612872597518\n",
      "epoch: 12, iter: 9750, train_loss: 0.05900801569223404, val_loss: 0.7846745837266278\n",
      "epoch: 12, iter: 9800, train_loss: 0.0722738977894187, val_loss: 0.7372217004656032\n",
      "epoch: 12, iter: 9850, train_loss: 0.06508662244305015, val_loss: 0.7432425786165675\n",
      "epoch: 12, iter: 9900, train_loss: 0.08763742595911025, val_loss: 0.7442998870922501\n",
      "epoch: 12, iter: 9950, train_loss: 0.06662465641275048, val_loss: 0.8000234656842651\n",
      "epoch: 12, iter: 10000, train_loss: 0.07835769098252059, val_loss: 0.8088114700119966\n",
      "epoch: 12, iter: 10050, train_loss: 0.0844253851659596, val_loss: 0.7804047306821604\n",
      "epoch: 12, iter: 10100, train_loss: 0.08464142756536602, val_loss: 0.7360226423687236\n",
      "epoch: 12, iter: 10150, train_loss: 0.08690875176340342, val_loss: 0.7535181505854722\n",
      "epoch: 13, iter: 10200, train_loss: 0.039318521488457915, val_loss: 0.7754297731029001\n",
      "epoch: 13, iter: 10250, train_loss: 0.0648417681735009, val_loss: 0.7757165511702276\n",
      "epoch: 13, iter: 10300, train_loss: 0.04702071577310562, val_loss: 0.8119301323298436\n",
      "epoch: 13, iter: 10350, train_loss: 0.05334219264797866, val_loss: 0.7911389965540284\n",
      "epoch: 13, iter: 10400, train_loss: 0.06582335464656353, val_loss: 0.7905438480673322\n",
      "epoch: 13, iter: 10450, train_loss: 0.06318970182910562, val_loss: 0.8008203211293858\n",
      "epoch: 13, iter: 10500, train_loss: 0.06669867912307381, val_loss: 0.8396117106364791\n",
      "epoch: 13, iter: 10550, train_loss: 0.09077665165066719, val_loss: 0.7969068494761825\n",
      "epoch: 13, iter: 10600, train_loss: 0.07928979126736521, val_loss: 0.7785706011353025\n",
      "epoch: 13, iter: 10650, train_loss: 0.09445069372653961, val_loss: 0.7930106640241708\n",
      "epoch: 13, iter: 10700, train_loss: 0.0608434997452423, val_loss: 0.7443406517338601\n",
      "epoch: 13, iter: 10750, train_loss: 0.05946344943717122, val_loss: 0.741722901915289\n",
      "epoch: 13, iter: 10800, train_loss: 0.058307109642773865, val_loss: 0.762405545468543\n",
      "epoch: 13, iter: 10850, train_loss: 0.07397030217573047, val_loss: 0.8172556716165725\n",
      "epoch: 13, iter: 10900, train_loss: 0.0854146756976843, val_loss: 0.787014769710553\n",
      "epoch: 14, iter: 10950, train_loss: 0.0018480876833200455, val_loss: 0.7680706573519737\n",
      "epoch: 14, iter: 11000, train_loss: 0.047487958008423446, val_loss: 0.7843204167238467\n",
      "epoch: 14, iter: 11050, train_loss: 0.04240041984012351, val_loss: 0.7926340858647778\n",
      "epoch: 14, iter: 11100, train_loss: 0.03244621215388179, val_loss: 0.7729838432589914\n",
      "epoch: 14, iter: 11150, train_loss: 0.03916433449601755, val_loss: 0.781018045582589\n",
      "epoch: 14, iter: 11200, train_loss: 0.041977408742532134, val_loss: 0.8034855943576545\n",
      "epoch: 14, iter: 11250, train_loss: 0.035579184526577594, val_loss: 0.8005014979725431\n",
      "epoch: 14, iter: 11300, train_loss: 0.03248868980910629, val_loss: 0.8075090292247997\n",
      "epoch: 14, iter: 11350, train_loss: 0.037677716952748595, val_loss: 0.8689073676801031\n",
      "epoch: 14, iter: 11400, train_loss: 0.06111642165575176, val_loss: 0.8041072982321879\n",
      "epoch: 14, iter: 11450, train_loss: 0.05509000284131616, val_loss: 0.7783886060403411\n",
      "epoch: 14, iter: 11500, train_loss: 0.06989024289883673, val_loss: 0.7916711579272702\n",
      "epoch: 14, iter: 11550, train_loss: 0.06475540867075325, val_loss: 0.7518788747916556\n",
      "epoch: 14, iter: 11600, train_loss: 0.06628472304902971, val_loss: 0.7872558340525172\n",
      "epoch: 14, iter: 11650, train_loss: 0.060543031916022304, val_loss: 0.8840906280241195\n",
      "epoch: 14, iter: 11700, train_loss: 0.07435330286622048, val_loss: 0.7970864906622346\n",
      "epoch: 15, iter: 11750, train_loss: 0.032624748134985566, val_loss: 0.8686884550531958\n",
      "epoch: 15, iter: 11800, train_loss: 0.06984065888449549, val_loss: 0.7900798993695314\n",
      "epoch: 15, iter: 11850, train_loss: 0.04718663229607046, val_loss: 0.7897738223053088\n",
      "epoch: 15, iter: 11900, train_loss: 0.03422444859519601, val_loss: 0.8126342760719312\n",
      "epoch: 15, iter: 11950, train_loss: 0.047826792495325204, val_loss: 0.8119805656895516\n",
      "epoch: 15, iter: 12000, train_loss: 0.05819427732378244, val_loss: 0.8959321055063016\n",
      "epoch: 15, iter: 12050, train_loss: 0.05762006721924991, val_loss: 0.8323528510370072\n",
      "epoch: 15, iter: 12100, train_loss: 0.0722999841812998, val_loss: 0.9044190453495949\n",
      "epoch: 15, iter: 12150, train_loss: 0.06791287120431662, val_loss: 0.8655229655990175\n",
      "epoch: 15, iter: 12200, train_loss: 0.0648123860079795, val_loss: 0.8502306376293207\n",
      "epoch: 15, iter: 12250, train_loss: 0.058003362035378814, val_loss: 0.8619870625104115\n",
      "epoch: 15, iter: 12300, train_loss: 0.061518792118877175, val_loss: 0.8558546992813706\n",
      "epoch: 15, iter: 12350, train_loss: 0.059748282637447116, val_loss: 0.8056597672640138\n",
      "epoch: 15, iter: 12400, train_loss: 0.05547623321413994, val_loss: 0.805743002303087\n",
      "epoch: 15, iter: 12450, train_loss: 0.050603198357857766, val_loss: 0.8553236434414129\n",
      "epoch: 15, iter: 12500, train_loss: 0.060117905344814065, val_loss: 0.822844623949877\n",
      "epoch: 16, iter: 12550, train_loss: 0.02157166269607842, val_loss: 0.7946712321536556\n",
      "epoch: 16, iter: 12600, train_loss: 0.02769945320440456, val_loss: 0.8267652677122954\n",
      "epoch: 16, iter: 12650, train_loss: 0.032808556430973114, val_loss: 0.8423235808398314\n",
      "epoch: 16, iter: 12700, train_loss: 0.03682730107102543, val_loss: 0.8990483975904003\n",
      "epoch: 16, iter: 12750, train_loss: 0.03521902428939939, val_loss: 0.8481125833502241\n",
      "epoch: 16, iter: 12800, train_loss: 0.04858913536183536, val_loss: 0.8372249217929354\n",
      "epoch: 16, iter: 12850, train_loss: 0.0484542474988848, val_loss: 0.7975188229873682\n",
      "epoch: 16, iter: 12900, train_loss: 0.040018043834716084, val_loss: 0.9014352003859866\n",
      "epoch: 16, iter: 12950, train_loss: 0.05249342308845371, val_loss: 0.9031138131572942\n",
      "epoch: 16, iter: 13000, train_loss: 0.06633460931479931, val_loss: 0.8765256797811788\n",
      "epoch: 16, iter: 13050, train_loss: 0.08481896520592272, val_loss: 0.822671291744633\n",
      "epoch: 16, iter: 13100, train_loss: 0.06604077497497202, val_loss: 0.7910716057203377\n",
      "epoch: 16, iter: 13150, train_loss: 0.058764814967289566, val_loss: 0.9013157967169574\n",
      "epoch: 16, iter: 13200, train_loss: 0.07352261224761605, val_loss: 0.8183747328770389\n",
      "epoch: 16, iter: 13250, train_loss: 0.06812663000077009, val_loss: 0.841887656670467\n",
      "epoch: 17, iter: 13300, train_loss: 0.0033603989519178866, val_loss: 0.8710148634424635\n",
      "epoch: 17, iter: 13350, train_loss: 0.04190637754742056, val_loss: 0.8488801328619574\n",
      "epoch: 17, iter: 13400, train_loss: 0.03515585215995088, val_loss: 0.8308034689183448\n",
      "epoch: 17, iter: 13450, train_loss: 0.04012118474813178, val_loss: 0.8426823385392025\n",
      "epoch: 17, iter: 13500, train_loss: 0.039670180859975514, val_loss: 0.9045765573621556\n",
      "epoch: 17, iter: 13550, train_loss: 0.04088769826106727, val_loss: 0.860326369951485\n",
      "epoch: 17, iter: 13600, train_loss: 0.04507323235273361, val_loss: 0.8598398221716\n",
      "epoch: 17, iter: 13650, train_loss: 0.038096814113669095, val_loss: 0.8833105837463573\n",
      "epoch: 17, iter: 13700, train_loss: 0.05113875900395214, val_loss: 0.9572126512314864\n",
      "epoch: 17, iter: 13750, train_loss: 0.048994588837958875, val_loss: 0.8715019616161942\n",
      "epoch: 17, iter: 13800, train_loss: 0.0502109106304124, val_loss: 0.9181252397169732\n",
      "epoch: 17, iter: 13850, train_loss: 0.06135380546562374, val_loss: 0.9207624895557477\n",
      "epoch: 17, iter: 13900, train_loss: 0.04912449724972248, val_loss: 0.8816729495479803\n",
      "epoch: 17, iter: 13950, train_loss: 0.05634234809316695, val_loss: 0.8846062356309526\n",
      "epoch: 17, iter: 14000, train_loss: 0.052853434327989814, val_loss: 0.862367090810636\n",
      "epoch: 17, iter: 14050, train_loss: 0.054123421786352995, val_loss: 0.9218513517622735\n",
      "epoch: 18, iter: 14100, train_loss: 0.021373380520381034, val_loss: 0.919633614029854\n",
      "epoch: 18, iter: 14150, train_loss: 0.04578655574005097, val_loss: 0.9004490758962692\n",
      "epoch: 18, iter: 14200, train_loss: 0.04740939365932718, val_loss: 0.8357669716807687\n",
      "epoch: 18, iter: 14250, train_loss: 0.03414207442197949, val_loss: 0.8858268605485843\n",
      "epoch: 18, iter: 14300, train_loss: 0.03575471887597814, val_loss: 0.8905981289353341\n",
      "epoch: 18, iter: 14350, train_loss: 0.035461703976616264, val_loss: 0.8895644456337971\n",
      "epoch: 18, iter: 14400, train_loss: 0.05698956719134003, val_loss: 0.8986850654243663\n",
      "epoch: 18, iter: 14450, train_loss: 0.06206151754013263, val_loss: 0.8413160157621287\n",
      "epoch: 18, iter: 14500, train_loss: 0.04464808975346386, val_loss: 0.8984009866501875\n",
      "epoch: 18, iter: 14550, train_loss: 0.03844419873086736, val_loss: 0.8997363068495586\n",
      "epoch: 18, iter: 14600, train_loss: 0.04492083210498095, val_loss: 0.8677161335945129\n",
      "epoch: 18, iter: 14650, train_loss: 0.0409896646020934, val_loss: 0.8727258599487839\n",
      "epoch: 18, iter: 14700, train_loss: 0.057494366948958486, val_loss: 0.8777607710687978\n",
      "epoch: 18, iter: 14750, train_loss: 0.0605877547012642, val_loss: 0.8621692668860126\n",
      "epoch: 18, iter: 14800, train_loss: 0.041582628535106775, val_loss: 0.882074513253133\n",
      "epoch: 18, iter: 14850, train_loss: 0.055545652317814526, val_loss: 0.9033230368498784\n",
      "epoch: 19, iter: 14900, train_loss: 0.0387676063971594, val_loss: 0.9141267230556269\n",
      "epoch: 19, iter: 14950, train_loss: 0.03709326969925314, val_loss: 0.888007925764011\n",
      "epoch: 19, iter: 15000, train_loss: 0.026235138492193073, val_loss: 0.8823499542892359\n",
      "epoch: 19, iter: 15050, train_loss: 0.02807691546389833, val_loss: 0.9307808256263186\n",
      "epoch: 19, iter: 15100, train_loss: 0.0344140160549432, val_loss: 0.8956624801940979\n",
      "epoch: 19, iter: 15150, train_loss: 0.02825428172829561, val_loss: 0.9044339756487282\n",
      "epoch: 19, iter: 15200, train_loss: 0.030925824841251597, val_loss: 0.8254104947588247\n",
      "epoch: 19, iter: 15250, train_loss: 0.02917030650191009, val_loss: 0.8915170396968817\n",
      "epoch: 19, iter: 15300, train_loss: 0.03425752743147314, val_loss: 0.9379549203974427\n",
      "epoch: 19, iter: 15350, train_loss: 0.04885394633281976, val_loss: 0.9796398397843549\n",
      "epoch: 19, iter: 15400, train_loss: 0.05164714719168842, val_loss: 0.910581249150501\n",
      "epoch: 19, iter: 15450, train_loss: 0.05371559502091259, val_loss: 0.9349760008845359\n",
      "epoch: 19, iter: 15500, train_loss: 0.03275340732303448, val_loss: 0.9025239825343631\n",
      "epoch: 19, iter: 15550, train_loss: 0.0590960365626961, val_loss: 0.9786449239891806\n",
      "epoch: 19, iter: 15600, train_loss: 0.05646520002745092, val_loss: 0.923515721491188\n",
      "epoch: 20, iter: 15650, train_loss: 0.012084663193672896, val_loss: 0.947957472436747\n",
      "epoch: 20, iter: 15700, train_loss: 0.05224273432977498, val_loss: 0.8587205061677156\n",
      "epoch: 20, iter: 15750, train_loss: 0.03133800671668723, val_loss: 0.860716013866625\n",
      "epoch: 20, iter: 15800, train_loss: 0.02815338089480065, val_loss: 0.845914173752639\n",
      "epoch: 20, iter: 15850, train_loss: 0.02301355908391997, val_loss: 0.8834106839576344\n",
      "epoch: 20, iter: 15900, train_loss: 0.019312139602261594, val_loss: 0.8597079872325727\n",
      "epoch: 20, iter: 15950, train_loss: 0.031232987088151275, val_loss: 0.8874183075063548\n",
      "epoch: 20, iter: 16000, train_loss: 0.026242942763492465, val_loss: 0.8791611925431877\n",
      "epoch: 20, iter: 16050, train_loss: 0.03585997710237279, val_loss: 0.9476874352070936\n",
      "epoch: 20, iter: 16100, train_loss: 0.05285002863616683, val_loss: 0.9268190884476255\n",
      "epoch: 20, iter: 16150, train_loss: 0.04537258363328874, val_loss: 0.8907163427893523\n",
      "epoch: 20, iter: 16200, train_loss: 0.03136449469951913, val_loss: 0.8967085858439184\n",
      "epoch: 20, iter: 16250, train_loss: 0.04753699181601405, val_loss: 0.9212657767496292\n",
      "epoch: 20, iter: 16300, train_loss: 0.048221243284642695, val_loss: 0.9168027567256029\n",
      "epoch: 20, iter: 16350, train_loss: 0.05462860747706145, val_loss: 0.9613324081062511\n",
      "epoch: 20, iter: 16400, train_loss: 0.0623482121527195, val_loss: 0.9419879328673053\n",
      "epoch: 21, iter: 16450, train_loss: 0.04646016452461481, val_loss: 0.9767896941133366\n",
      "epoch: 21, iter: 16500, train_loss: 0.05390593041665852, val_loss: 0.9080661715595586\n",
      "epoch: 21, iter: 16550, train_loss: 0.05462462944095023, val_loss: 0.9492103140445272\n",
      "epoch: 21, iter: 16600, train_loss: 0.05016780269448645, val_loss: 0.8944257043159691\n",
      "epoch: 21, iter: 16650, train_loss: 0.03530663163634017, val_loss: 0.9320032891764003\n",
      "epoch: 21, iter: 16700, train_loss: 0.043372846907004714, val_loss: 0.9037932721292896\n",
      "epoch: 21, iter: 16750, train_loss: 0.03899919446092099, val_loss: 0.8905465796494939\n",
      "epoch: 21, iter: 16800, train_loss: 0.03427427432034165, val_loss: 0.8751691058752643\n",
      "epoch: 21, iter: 16850, train_loss: 0.024113447566051036, val_loss: 0.9019005154348483\n",
      "epoch: 21, iter: 16900, train_loss: 0.02768415997561533, val_loss: 0.898461622227529\n",
      "epoch: 21, iter: 16950, train_loss: 0.039140858508180824, val_loss: 0.9171376409614163\n",
      "epoch: 21, iter: 17000, train_loss: 0.034669605016242715, val_loss: 0.9207083025745525\n",
      "epoch: 21, iter: 17050, train_loss: 0.0418557898607105, val_loss: 0.8824287949094347\n",
      "epoch: 21, iter: 17100, train_loss: 0.029157056151889266, val_loss: 0.905989992675508\n",
      "epoch: 21, iter: 17150, train_loss: 0.03499515245901421, val_loss: 0.9226785319246305\n",
      "epoch: 21, iter: 17200, train_loss: 0.052970658629201355, val_loss: 0.9350149635296718\n",
      "epoch: 22, iter: 17250, train_loss: 0.03669665881665424, val_loss: 0.8889241358087321\n",
      "epoch: 22, iter: 17300, train_loss: 0.02862839294364676, val_loss: 0.8863898375231749\n",
      "epoch: 22, iter: 17350, train_loss: 0.02080039762426168, val_loss: 0.8718211625222188\n",
      "epoch: 22, iter: 17400, train_loss: 0.026739206837373786, val_loss: 0.8845999941324733\n",
      "epoch: 22, iter: 17450, train_loss: 0.0322888997499831, val_loss: 0.9838776866531675\n",
      "epoch: 22, iter: 17500, train_loss: 0.04119083288591355, val_loss: 0.9217958483536532\n",
      "epoch: 22, iter: 17550, train_loss: 0.04292606892297044, val_loss: 0.8903349824961583\n",
      "epoch: 22, iter: 17600, train_loss: 0.03844522834056988, val_loss: 0.9024175962634907\n",
      "epoch: 22, iter: 17650, train_loss: 0.03086170433089137, val_loss: 0.8785103282351403\n",
      "epoch: 22, iter: 17700, train_loss: 0.03427941506495699, val_loss: 0.8854737388100594\n",
      "epoch: 22, iter: 17750, train_loss: 0.023086589965969323, val_loss: 0.9461004208227631\n",
      "epoch: 22, iter: 17800, train_loss: 0.03822382704238407, val_loss: 0.9387124091576619\n",
      "epoch: 22, iter: 17850, train_loss: 0.04442566636716947, val_loss: 0.9826906665115599\n",
      "epoch: 22, iter: 17900, train_loss: 0.04108451640233397, val_loss: 0.9670052532177822\n",
      "epoch: 22, iter: 17950, train_loss: 0.05591162740951404, val_loss: 0.9625455551086717\n",
      "epoch: 23, iter: 18000, train_loss: 0.015530229853466153, val_loss: 0.9967986058657337\n",
      "epoch: 23, iter: 18050, train_loss: 0.05059060724917799, val_loss: 0.9390155198467764\n",
      "epoch: 23, iter: 18100, train_loss: 0.0382020714902319, val_loss: 0.9656396288970474\n",
      "epoch: 23, iter: 18150, train_loss: 0.03725732574530412, val_loss: 0.904836265809217\n",
      "epoch: 23, iter: 18200, train_loss: 0.03868409714195877, val_loss: 0.9188127326927368\n",
      "epoch: 23, iter: 18250, train_loss: 0.03614493069122546, val_loss: 0.9182398196808093\n",
      "epoch: 23, iter: 18300, train_loss: 0.046242381692864, val_loss: 0.9660075416041028\n",
      "epoch: 23, iter: 18350, train_loss: 0.036491717717144635, val_loss: 0.9321543557249057\n",
      "epoch: 23, iter: 18400, train_loss: 0.040055519149173054, val_loss: 0.9444808014638865\n",
      "epoch: 23, iter: 18450, train_loss: 0.0277121708355844, val_loss: 0.9412983674437377\n",
      "epoch: 23, iter: 18500, train_loss: 0.028831702973111533, val_loss: 0.9766485990042899\n",
      "epoch: 23, iter: 18550, train_loss: 0.03731839477317408, val_loss: 0.9107857052307979\n",
      "epoch: 23, iter: 18600, train_loss: 0.03096300127916038, val_loss: 0.9506206669055732\n",
      "epoch: 23, iter: 18650, train_loss: 0.03971186340320856, val_loss: 0.9380240498264883\n",
      "epoch: 23, iter: 18700, train_loss: 0.029380880936514586, val_loss: 1.02648468809143\n",
      "epoch: 23, iter: 18750, train_loss: 0.029778943811543286, val_loss: 0.929791112234638\n",
      "epoch: 24, iter: 18800, train_loss: 0.02752939012250863, val_loss: 0.9397613221103218\n",
      "epoch: 24, iter: 18850, train_loss: 0.02915904798603151, val_loss: 0.9496162735922321\n",
      "epoch: 24, iter: 18900, train_loss: 0.01813831108622253, val_loss: 0.9124117450919121\n",
      "epoch: 24, iter: 18950, train_loss: 0.026965085424890275, val_loss: 0.9632336633030776\n",
      "epoch: 24, iter: 19000, train_loss: 0.04051425052108243, val_loss: 0.9664045524824957\n",
      "epoch: 24, iter: 19050, train_loss: 0.029651754111982884, val_loss: 0.9219626505283793\n",
      "epoch: 24, iter: 19100, train_loss: 0.028764157383120617, val_loss: 0.9322935473767056\n",
      "epoch: 24, iter: 19150, train_loss: 0.040426795491948726, val_loss: 0.9694104240198803\n",
      "epoch: 24, iter: 19200, train_loss: 0.035310983978561125, val_loss: 0.9176014839274109\n",
      "epoch: 24, iter: 19250, train_loss: 0.02977499696891755, val_loss: 0.9850953563952901\n",
      "epoch: 24, iter: 19300, train_loss: 0.03596416703076102, val_loss: 0.957333359463959\n",
      "epoch: 24, iter: 19350, train_loss: 0.03347427104890812, val_loss: 0.9849261862647002\n",
      "epoch: 24, iter: 19400, train_loss: 0.021785087230382486, val_loss: 1.0487430833137719\n",
      "epoch: 24, iter: 19450, train_loss: 0.034820704172016125, val_loss: 0.9807798148720128\n",
      "epoch: 24, iter: 19500, train_loss: 0.03400027440395206, val_loss: 0.9799375068989529\n",
      "epoch: 24, iter: 19550, train_loss: 0.03780928676525946, val_loss: 0.9898682694146588\n",
      "epoch: 25, iter: 19600, train_loss: 0.029615417601307856, val_loss: 1.030168161745284\n",
      "epoch: 25, iter: 19650, train_loss: 0.03543373653665185, val_loss: 1.0814043199940093\n",
      "epoch: 25, iter: 19700, train_loss: 0.031581691508181395, val_loss: 1.0232759571758805\n",
      "epoch: 25, iter: 19750, train_loss: 0.04601179761928506, val_loss: 0.9819400679723472\n",
      "epoch: 25, iter: 19800, train_loss: 0.03395151709672064, val_loss: 0.9800918852068057\n",
      "epoch: 25, iter: 19850, train_loss: 0.03787363907787949, val_loss: 0.9761945434436676\n",
      "epoch: 25, iter: 19900, train_loss: 0.03617326052393764, val_loss: 0.9556186706966655\n",
      "epoch: 25, iter: 19950, train_loss: 0.031962887526024136, val_loss: 1.0065564431582288\n",
      "epoch: 25, iter: 20000, train_loss: 0.05473625818733126, val_loss: 1.0135350206475349\n",
      "epoch: 25, iter: 20050, train_loss: 0.033174031656235455, val_loss: 1.0017470986979782\n",
      "epoch: 25, iter: 20100, train_loss: 0.03880382875911891, val_loss: 0.99561334985077\n",
      "epoch: 25, iter: 20150, train_loss: 0.03803500141017139, val_loss: 0.9565963235440528\n",
      "epoch: 25, iter: 20200, train_loss: 0.028258164399303495, val_loss: 1.02619647400774\n",
      "epoch: 25, iter: 20250, train_loss: 0.025971524562919512, val_loss: 1.0028566770303022\n",
      "epoch: 25, iter: 20300, train_loss: 0.03883320097113028, val_loss: 1.0674733514808545\n",
      "epoch: 26, iter: 20350, train_loss: 0.017207058425992728, val_loss: 1.0469024484134783\n",
      "epoch: 26, iter: 20400, train_loss: 0.043440533473622055, val_loss: 0.9901342395764248\n",
      "epoch: 26, iter: 20450, train_loss: 0.04308761494234204, val_loss: 0.9958385825157166\n",
      "epoch: 26, iter: 20500, train_loss: 0.02946856088703498, val_loss: 1.0044848554453272\n",
      "epoch: 26, iter: 20550, train_loss: 0.0400520079897251, val_loss: 0.9961240739579413\n",
      "epoch: 26, iter: 20600, train_loss: 0.04436226917663589, val_loss: 0.9551435342639875\n",
      "epoch: 26, iter: 20650, train_loss: 0.027444455847144125, val_loss: 0.957185532826527\n",
      "epoch: 26, iter: 20700, train_loss: 0.02545033732778393, val_loss: 0.9576879785319042\n",
      "epoch: 26, iter: 20750, train_loss: 0.02472397239645943, val_loss: 1.0089908234632698\n",
      "epoch: 26, iter: 20800, train_loss: 0.0296315934904851, val_loss: 0.9902261264005284\n",
      "epoch: 26, iter: 20850, train_loss: 0.03063333035679534, val_loss: 0.9872204120371751\n",
      "epoch: 26, iter: 20900, train_loss: 0.03346257415600121, val_loss: 1.0174277207464169\n",
      "epoch: 26, iter: 20950, train_loss: 0.03455750158755109, val_loss: 1.054047665873151\n",
      "epoch: 26, iter: 21000, train_loss: 0.0384917796892114, val_loss: 1.0240752483439293\n",
      "epoch: 26, iter: 21050, train_loss: 0.03899439678178169, val_loss: 1.0085125736370208\n",
      "epoch: 26, iter: 21100, train_loss: 0.05546486366540194, val_loss: 1.036119959821367\n",
      "epoch: 27, iter: 21150, train_loss: 0.009122294188127853, val_loss: 0.9732771433272939\n",
      "epoch: 27, iter: 21200, train_loss: 0.020132591656874865, val_loss: 0.9845736310550361\n",
      "epoch: 27, iter: 21250, train_loss: 0.02411948179738829, val_loss: 1.007855665816623\n",
      "epoch: 27, iter: 21300, train_loss: 0.022331763761176262, val_loss: 0.9959887060200333\n",
      "epoch: 27, iter: 21350, train_loss: 0.02416067911486607, val_loss: 1.0213170211975742\n",
      "epoch: 27, iter: 21400, train_loss: 0.030798827007529325, val_loss: 1.0218593279837043\n",
      "epoch: 27, iter: 21450, train_loss: 0.04642712255707011, val_loss: 1.0771369920794371\n",
      "epoch: 27, iter: 21500, train_loss: 0.034139406520407645, val_loss: 0.9883622003683619\n",
      "epoch: 27, iter: 21550, train_loss: 0.026700273085734808, val_loss: 0.9865449206654433\n",
      "epoch: 27, iter: 21600, train_loss: 0.04026071988046169, val_loss: 0.9702870181411695\n",
      "epoch: 27, iter: 21650, train_loss: 0.027170162808615714, val_loss: 0.9610240368326758\n",
      "epoch: 27, iter: 21700, train_loss: 0.030652789745945482, val_loss: 1.0372248348916413\n",
      "epoch: 27, iter: 21750, train_loss: 0.03262773732072674, val_loss: 1.0283614112313386\n",
      "epoch: 27, iter: 21800, train_loss: 0.027190383746055886, val_loss: 0.9910335042484247\n",
      "epoch: 27, iter: 21850, train_loss: 0.034021673362585714, val_loss: 1.053748025541093\n",
      "epoch: 28, iter: 21900, train_loss: 0.0019497460429556668, val_loss: 1.0663306897233247\n",
      "epoch: 28, iter: 21950, train_loss: 0.07418649759609253, val_loss: 1.1687327927085245\n",
      "epoch: 28, iter: 22000, train_loss: 0.08306381375994533, val_loss: 1.0381423024235257\n",
      "epoch: 28, iter: 22050, train_loss: 0.04084051748737693, val_loss: 1.0419361578051451\n",
      "epoch: 28, iter: 22100, train_loss: 0.03837229770142585, val_loss: 1.0092923156205256\n",
      "epoch: 28, iter: 22150, train_loss: 0.0493056615581736, val_loss: 0.9799780043636918\n",
      "epoch: 28, iter: 22200, train_loss: 0.04127032794523984, val_loss: 0.9388077322654663\n",
      "epoch: 28, iter: 22250, train_loss: 0.026629299743071898, val_loss: 0.9344124866139357\n",
      "epoch: 28, iter: 22300, train_loss: 0.026323729779105635, val_loss: 0.9521825814702708\n",
      "epoch: 28, iter: 22350, train_loss: 0.02512181121855974, val_loss: 0.9367717798728092\n",
      "epoch: 28, iter: 22400, train_loss: 0.028663148167543114, val_loss: 0.9862437371615391\n",
      "epoch: 28, iter: 22450, train_loss: 0.02077965664095245, val_loss: 0.940541317413567\n",
      "epoch: 28, iter: 22500, train_loss: 0.01268060936301481, val_loss: 0.9536513862716165\n",
      "epoch: 28, iter: 22550, train_loss: 0.014849917220708449, val_loss: 1.018954922818834\n",
      "epoch: 28, iter: 22600, train_loss: 0.015706103153061122, val_loss: 0.9619469365496545\n",
      "epoch: 28, iter: 22650, train_loss: 0.02121613576018717, val_loss: 1.0346090761339588\n",
      "epoch: 29, iter: 22700, train_loss: 0.018471945164492354, val_loss: 1.1092679158897156\n",
      "epoch: 29, iter: 22750, train_loss: 0.027406591208418832, val_loss: 1.0494703625797466\n",
      "epoch: 29, iter: 22800, train_loss: 0.029273795431945474, val_loss: 1.0027084096222167\n",
      "epoch: 29, iter: 22850, train_loss: 0.025661723910598084, val_loss: 1.0175430875295286\n",
      "epoch: 29, iter: 22900, train_loss: 0.02543347505910788, val_loss: 1.0019659369614473\n",
      "epoch: 29, iter: 22950, train_loss: 0.025571398466126993, val_loss: 0.9960348006266697\n",
      "epoch: 29, iter: 23000, train_loss: 0.01915703029371798, val_loss: 0.9957764404974166\n",
      "epoch: 29, iter: 23050, train_loss: 0.016449983296479332, val_loss: 0.969001210893795\n",
      "epoch: 29, iter: 23100, train_loss: 0.023389574540778994, val_loss: 1.0241242267523603\n",
      "epoch: 29, iter: 23150, train_loss: 0.022067770836292765, val_loss: 1.019732238001125\n",
      "epoch: 29, iter: 23200, train_loss: 0.030973694864660502, val_loss: 1.0657949903208739\n",
      "epoch: 29, iter: 23250, train_loss: 0.034625996093964204, val_loss: 1.0535310849452475\n",
      "epoch: 29, iter: 23300, train_loss: 0.03375577711558435, val_loss: 1.0577118187952952\n",
      "epoch: 29, iter: 23350, train_loss: 0.02939928168663755, val_loss: 1.059962818909223\n",
      "epoch: 29, iter: 23400, train_loss: 0.029041541205951944, val_loss: 1.1508127741373269\n",
      "epoch: 29, iter: 23450, train_loss: 0.043346499907784164, val_loss: 1.0348790301259156\n",
      "best loss:  0.5481929880608419\n",
      "Born Again...\n",
      "/nfs/home/wushangrui/.conda/envs/pytorch1.9-cuda11-wushangrui/lib/python3.8/site-packages/torch/nn/functional.py:2741: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "epoch: 0, iter: 23500, train_loss: 1.9791463899612427, val_loss: 2.185782251843981\n",
      "epoch: 0, iter: 23550, train_loss: 1.6985374617576598, val_loss: 2.02112579953139\n",
      "epoch: 0, iter: 23600, train_loss: 1.5603216147422792, val_loss: 1.9223927084807377\n",
      "epoch: 0, iter: 23650, train_loss: 1.5512554669380187, val_loss: 1.8925893800273823\n",
      "epoch: 0, iter: 23700, train_loss: 1.478780734539032, val_loss: 1.7593949835771208\n",
      "epoch: 0, iter: 23750, train_loss: 1.4134979248046875, val_loss: 1.7083216191856725\n",
      "epoch: 0, iter: 23800, train_loss: 1.3890975403785706, val_loss: 1.752377480458302\n",
      "epoch: 0, iter: 23850, train_loss: 1.3743230080604554, val_loss: 1.6763304980697147\n",
      "epoch: 0, iter: 23900, train_loss: 1.3454178261756897, val_loss: 1.6406572799014438\n",
      "epoch: 0, iter: 23950, train_loss: 1.2943562746047974, val_loss: 1.5996062155741795\n",
      "epoch: 0, iter: 24000, train_loss: 1.2650869798660278, val_loss: 1.5616084504279362\n",
      "epoch: 0, iter: 24050, train_loss: 1.2925216996669768, val_loss: 1.8413048716867046\n",
      "epoch: 0, iter: 24100, train_loss: 1.3305283212661743, val_loss: 1.538722234926406\n",
      "epoch: 0, iter: 24150, train_loss: 1.2247407555580139, val_loss: 1.5324739202572282\n",
      "epoch: 0, iter: 24200, train_loss: 1.1936890542507173, val_loss: 1.4712738413719615\n",
      "epoch: 1, iter: 24250, train_loss: 0.1918652296066284, val_loss: 1.449759315533243\n",
      "epoch: 1, iter: 24300, train_loss: 1.1317758607864379, val_loss: 1.4037473520655541\n",
      "epoch: 1, iter: 24350, train_loss: 1.1007257616519928, val_loss: 1.3436522461046838\n",
      "epoch: 1, iter: 24400, train_loss: 1.051827722787857, val_loss: 1.3413087121999947\n",
      "epoch: 1, iter: 24450, train_loss: 1.0415274214744568, val_loss: 1.2592756057241161\n",
      "epoch: 1, iter: 24500, train_loss: 1.0258730173110961, val_loss: 1.25408659163554\n",
      "epoch: 1, iter: 24550, train_loss: 0.9899147439002991, val_loss: 1.2225105667569836\n",
      "epoch: 1, iter: 24600, train_loss: 0.920984239578247, val_loss: 1.1543620688140772\n",
      "epoch: 1, iter: 24650, train_loss: 0.9242501330375671, val_loss: 1.1918265914461414\n",
      "epoch: 1, iter: 24700, train_loss: 0.9411156177520752, val_loss: 1.0998772029664106\n",
      "epoch: 1, iter: 24750, train_loss: 0.8939692223072052, val_loss: 1.1225291505740707\n",
      "epoch: 1, iter: 24800, train_loss: 0.8620647501945495, val_loss: 1.07857450823875\n",
      "epoch: 1, iter: 24850, train_loss: 0.8692606067657471, val_loss: 1.0608920230986967\n",
      "epoch: 1, iter: 24900, train_loss: 0.8372610211372375, val_loss: 1.0758540383569755\n",
      "epoch: 1, iter: 24950, train_loss: 0.8245924627780914, val_loss: 1.0287850871207609\n",
      "epoch: 1, iter: 25000, train_loss: 0.7998049366474151, val_loss: 0.9995805131401986\n",
      "epoch: 2, iter: 25050, train_loss: 0.4240371859073639, val_loss: 0.9509036590339272\n",
      "epoch: 2, iter: 25100, train_loss: 0.7583174765110016, val_loss: 0.9711183784114328\n",
      "epoch: 2, iter: 25150, train_loss: 0.7584037351608276, val_loss: 0.9679346137745365\n",
      "epoch: 2, iter: 25200, train_loss: 0.7216024959087372, val_loss: 0.9359245410390721\n",
      "epoch: 2, iter: 25250, train_loss: 0.7389899158477783, val_loss: 0.9529170993786709\n",
      "epoch: 2, iter: 25300, train_loss: 0.7498219043016434, val_loss: 0.9177387580750095\n",
      "epoch: 2, iter: 25350, train_loss: 0.709396710395813, val_loss: 0.8929837296722801\n",
      "epoch: 2, iter: 25400, train_loss: 0.6919010019302368, val_loss: 0.8813586212267541\n",
      "epoch: 2, iter: 25450, train_loss: 0.6713174933195114, val_loss: 0.8930566286205486\n",
      "epoch: 2, iter: 25500, train_loss: 0.687522538304329, val_loss: 0.9067383002323709\n",
      "epoch: 2, iter: 25550, train_loss: 0.7033563989400864, val_loss: 0.8929409942809184\n",
      "epoch: 2, iter: 25600, train_loss: 0.6778870439529419, val_loss: 0.8416591882705688\n",
      "epoch: 2, iter: 25650, train_loss: 0.658175567984581, val_loss: 0.8008601397845396\n",
      "epoch: 2, iter: 25700, train_loss: 0.6375675547122955, val_loss: 0.8239774506562835\n",
      "epoch: 2, iter: 25750, train_loss: 0.6534862500429154, val_loss: 0.7963170580043915\n",
      "epoch: 2, iter: 25800, train_loss: 0.6106274974346161, val_loss: 0.7965972070481367\n",
      "epoch: 3, iter: 25850, train_loss: 0.5094568985700607, val_loss: 0.7625195490326852\n",
      "epoch: 3, iter: 25900, train_loss: 0.5117720228433609, val_loss: 0.7841550259833123\n",
      "epoch: 3, iter: 25950, train_loss: 0.5665389597415924, val_loss: 0.7233068200812978\n",
      "epoch: 3, iter: 26000, train_loss: 0.5665920799970627, val_loss: 0.8100527895104354\n",
      "epoch: 3, iter: 26050, train_loss: 0.5651562291383744, val_loss: 0.7435665272983016\n",
      "epoch: 3, iter: 26100, train_loss: 0.537749651670456, val_loss: 0.7530506201990091\n",
      "epoch: 3, iter: 26150, train_loss: 0.5115303152799606, val_loss: 0.7407895666398819\n",
      "epoch: 3, iter: 26200, train_loss: 0.5240783751010895, val_loss: 0.6788911834643905\n",
      "epoch: 3, iter: 26250, train_loss: 0.5450629979372025, val_loss: 0.7061160324485438\n",
      "epoch: 3, iter: 26300, train_loss: 0.5456533527374268, val_loss: 0.6916524855194578\n",
      "epoch: 3, iter: 26350, train_loss: 0.48070814907550813, val_loss: 0.6892795917714477\n",
      "epoch: 3, iter: 26400, train_loss: 0.5003558880090714, val_loss: 0.6902478006994648\n",
      "epoch: 3, iter: 26450, train_loss: 0.48192493855953217, val_loss: 0.6762003310167106\n",
      "epoch: 3, iter: 26500, train_loss: 0.4847487622499466, val_loss: 0.6560272933191554\n",
      "epoch: 3, iter: 26550, train_loss: 0.4900916361808777, val_loss: 0.6402470818750418\n",
      "epoch: 4, iter: 26600, train_loss: 0.09451838552951813, val_loss: 0.6620533908628354\n",
      "epoch: 4, iter: 26650, train_loss: 0.41224533319473267, val_loss: 0.6497574706745756\n",
      "epoch: 4, iter: 26700, train_loss: 0.4170757207274437, val_loss: 0.6508581562406698\n",
      "epoch: 4, iter: 26750, train_loss: 0.4149825546145439, val_loss: 0.649597124878768\n",
      "epoch: 4, iter: 26800, train_loss: 0.4112163656949997, val_loss: 0.6224465157575668\n",
      "epoch: 4, iter: 26850, train_loss: 0.40639841467142107, val_loss: 0.5991592555289056\n",
      "epoch: 4, iter: 26900, train_loss: 0.4047873690724373, val_loss: 0.640655247079339\n",
      "epoch: 4, iter: 26950, train_loss: 0.39524377733469007, val_loss: 0.6057543786847668\n",
      "epoch: 4, iter: 27000, train_loss: 0.40236080914735795, val_loss: 0.6225075495850508\n",
      "epoch: 4, iter: 27050, train_loss: 0.3823926585912705, val_loss: 0.6398868932845486\n",
      "epoch: 4, iter: 27100, train_loss: 0.40678811967372897, val_loss: 0.5929778193592266\n",
      "epoch: 4, iter: 27150, train_loss: 0.42339924186468125, val_loss: 0.5943337472001459\n",
      "epoch: 4, iter: 27200, train_loss: 0.40487458974123003, val_loss: 0.6223547145439561\n",
      "epoch: 4, iter: 27250, train_loss: 0.38444320946931837, val_loss: 0.5881680652594111\n",
      "epoch: 4, iter: 27300, train_loss: 0.38897326827049256, val_loss: 0.579193481783958\n",
      "epoch: 4, iter: 27350, train_loss: 0.36635096549987795, val_loss: 0.5967614992408995\n",
      "epoch: 5, iter: 27400, train_loss: 0.20156846314668656, val_loss: 0.5912029640689777\n",
      "epoch: 5, iter: 27450, train_loss: 0.27377972811460494, val_loss: 0.6077864285866925\n",
      "epoch: 5, iter: 27500, train_loss: 0.29164798736572267, val_loss: 0.5722394541949983\n",
      "epoch: 5, iter: 27550, train_loss: 0.28872587710618974, val_loss: 0.5997182712623268\n",
      "epoch: 5, iter: 27600, train_loss: 0.2980381280183792, val_loss: 0.561704410963757\n",
      "epoch: 5, iter: 27650, train_loss: 0.3118333148956299, val_loss: 0.6041235358092436\n",
      "epoch: 5, iter: 27700, train_loss: 0.2877791830897331, val_loss: 0.6076936640177563\n",
      "epoch: 5, iter: 27750, train_loss: 0.28600276619195936, val_loss: 0.6009448963175913\n",
      "epoch: 5, iter: 27800, train_loss: 0.31806883424520493, val_loss: 0.5575104217240765\n",
      "epoch: 5, iter: 27850, train_loss: 0.2878881084918976, val_loss: 0.5799552192733546\n",
      "epoch: 5, iter: 27900, train_loss: 0.2976496276259422, val_loss: 0.5901865810155869\n",
      "epoch: 5, iter: 27950, train_loss: 0.3101334646344185, val_loss: 0.5664412620340943\n",
      "epoch: 5, iter: 28000, train_loss: 0.33439919739961627, val_loss: 0.558165687854123\n",
      "epoch: 5, iter: 28050, train_loss: 0.3351043674349785, val_loss: 0.5427261111652775\n",
      "epoch: 5, iter: 28100, train_loss: 0.3140027412772179, val_loss: 0.5344467559817491\n",
      "epoch: 5, iter: 28150, train_loss: 0.32968177169561386, val_loss: 0.5473303375350442\n",
      "epoch: 6, iter: 28200, train_loss: 0.1738676229119301, val_loss: 0.5369324066266892\n",
      "epoch: 6, iter: 28250, train_loss: 0.18280550807714463, val_loss: 0.5979160262141258\n",
      "epoch: 6, iter: 28300, train_loss: 0.18460796028375626, val_loss: 0.5947165743560549\n",
      "epoch: 6, iter: 28350, train_loss: 0.21064082518219948, val_loss: 0.6147465449609574\n",
      "epoch: 6, iter: 28400, train_loss: 0.2080054475367069, val_loss: 0.6044204607131375\n",
      "epoch: 6, iter: 28450, train_loss: 0.22171464517712594, val_loss: 0.5705744637425538\n",
      "epoch: 6, iter: 28500, train_loss: 0.20133233934640885, val_loss: 0.6043023884676064\n",
      "epoch: 6, iter: 28550, train_loss: 0.20683616295456886, val_loss: 0.6377264300159587\n",
      "epoch: 6, iter: 28600, train_loss: 0.2294590027630329, val_loss: 0.5964911103628243\n",
      "epoch: 6, iter: 28650, train_loss: 0.2346939289569855, val_loss: 0.5850396379353894\n",
      "epoch: 6, iter: 28700, train_loss: 0.24183020144701003, val_loss: 0.6246960766755851\n",
      "epoch: 6, iter: 28750, train_loss: 0.23456948339939118, val_loss: 0.5858518998524186\n",
      "epoch: 6, iter: 28800, train_loss: 0.2522644804418087, val_loss: 0.5420924873109076\n",
      "epoch: 6, iter: 28850, train_loss: 0.2361944431066513, val_loss: 0.5601010575036335\n",
      "epoch: 6, iter: 28900, train_loss: 0.237076702862978, val_loss: 0.5618123537415911\n",
      "epoch: 7, iter: 28950, train_loss: 0.060392629206180576, val_loss: 0.6079129656409002\n",
      "epoch: 7, iter: 29000, train_loss: 0.13131901882588864, val_loss: 0.6003722004639874\n",
      "epoch: 7, iter: 29050, train_loss: 0.11993588011711837, val_loss: 0.6278626812491447\n",
      "epoch: 7, iter: 29100, train_loss: 0.13443259242922068, val_loss: 0.620218297288676\n",
      "epoch: 7, iter: 29150, train_loss: 0.13194728188216687, val_loss: 0.6220265478844855\n",
      "epoch: 7, iter: 29200, train_loss: 0.14914191514253616, val_loss: 0.6053244890111267\n",
      "epoch: 7, iter: 29250, train_loss: 0.15169364243745803, val_loss: 0.650233324261228\n",
      "epoch: 7, iter: 29300, train_loss: 0.16297028943896294, val_loss: 0.6104007879639887\n",
      "epoch: 7, iter: 29350, train_loss: 0.15362410813570024, val_loss: 0.6127016110594865\n",
      "epoch: 7, iter: 29400, train_loss: 0.14819866098463536, val_loss: 0.5959823711472712\n",
      "epoch: 7, iter: 29450, train_loss: 0.15492739275097847, val_loss: 0.65438084778892\n",
      "epoch: 7, iter: 29500, train_loss: 0.16178891718387603, val_loss: 0.6134162296535103\n",
      "epoch: 7, iter: 29550, train_loss: 0.1610364158451557, val_loss: 0.6313659034337208\n",
      "epoch: 7, iter: 29600, train_loss: 0.17700157053768634, val_loss: 0.6012877254349411\n",
      "epoch: 7, iter: 29650, train_loss: 0.17300038188695907, val_loss: 0.5894385092197709\n",
      "epoch: 7, iter: 29700, train_loss: 0.18168975464999676, val_loss: 0.5970809236643421\n",
      "epoch: 8, iter: 29750, train_loss: 0.08135077595710755, val_loss: 0.6085589100031337\n",
      "epoch: 8, iter: 29800, train_loss: 0.08315679620951415, val_loss: 0.6149480968334113\n",
      "epoch: 8, iter: 29850, train_loss: 0.08787356015294791, val_loss: 0.6189547127978817\n",
      "epoch: 8, iter: 29900, train_loss: 0.08447496492415667, val_loss: 0.6794490308328799\n",
      "epoch: 8, iter: 29950, train_loss: 0.08444714158773423, val_loss: 0.6501590941741968\n",
      "epoch: 8, iter: 30000, train_loss: 0.09900925640016794, val_loss: 0.6662568642645125\n",
      "epoch: 8, iter: 30050, train_loss: 0.08817505806684495, val_loss: 0.6508166393276992\n",
      "epoch: 8, iter: 30100, train_loss: 0.10337618082761764, val_loss: 0.6970420069755263\n",
      "epoch: 8, iter: 30150, train_loss: 0.10467991013079882, val_loss: 0.6581538145899013\n",
      "epoch: 8, iter: 30200, train_loss: 0.11968653570860624, val_loss: 0.6473965051637334\n",
      "epoch: 8, iter: 30250, train_loss: 0.12613851457834244, val_loss: 0.648676125392033\n",
      "epoch: 8, iter: 30300, train_loss: 0.1260158784687519, val_loss: 0.6608954100472153\n",
      "epoch: 8, iter: 30350, train_loss: 0.11683872193098069, val_loss: 0.6454717888004461\n",
      "epoch: 8, iter: 30400, train_loss: 0.12690995529294014, val_loss: 0.6247007899982914\n",
      "epoch: 8, iter: 30450, train_loss: 0.13259437471628188, val_loss: 0.6416567541231775\n",
      "epoch: 9, iter: 30500, train_loss: 0.0014972226694226266, val_loss: 0.6429230126605672\n",
      "epoch: 9, iter: 30550, train_loss: 0.07912882931530475, val_loss: 0.7114425782754923\n",
      "epoch: 9, iter: 30600, train_loss: 0.0719101107865572, val_loss: 0.6610369811392134\n",
      "epoch: 9, iter: 30650, train_loss: 0.06498236468061805, val_loss: 0.6653495702394254\n",
      "epoch: 9, iter: 30700, train_loss: 0.06696853948757052, val_loss: 0.672290643309332\n",
      "epoch: 9, iter: 30750, train_loss: 0.05967111708596349, val_loss: 0.6681201118192855\n",
      "epoch: 9, iter: 30800, train_loss: 0.06513101203367114, val_loss: 0.7236607253171836\n",
      "epoch: 9, iter: 30850, train_loss: 0.0844821646437049, val_loss: 0.6900090391089202\n",
      "epoch: 9, iter: 30900, train_loss: 0.07383844392374157, val_loss: 0.6813148103512017\n",
      "epoch: 9, iter: 30950, train_loss: 0.0847535888850689, val_loss: 0.6910595691697613\n",
      "epoch: 9, iter: 31000, train_loss: 0.10224799104034901, val_loss: 0.6915326196296959\n",
      "epoch: 9, iter: 31050, train_loss: 0.09322880882769823, val_loss: 0.7016547383016841\n",
      "epoch: 9, iter: 31100, train_loss: 0.10691717147827148, val_loss: 0.6808130810405039\n",
      "epoch: 9, iter: 31150, train_loss: 0.0893590659275651, val_loss: 0.6920230541449444\n",
      "epoch: 9, iter: 31200, train_loss: 0.0815748723037541, val_loss: 0.6691168344514385\n",
      "epoch: 9, iter: 31250, train_loss: 0.08838336057960987, val_loss: 0.6774014571005371\n",
      "epoch: 10, iter: 31300, train_loss: 0.0275677577778697, val_loss: 0.7485491339188473\n",
      "epoch: 10, iter: 31350, train_loss: 0.05645166806876659, val_loss: 0.7452948750204341\n",
      "epoch: 10, iter: 31400, train_loss: 0.07553437316790224, val_loss: 0.7262390796925612\n",
      "epoch: 10, iter: 31450, train_loss: 0.061408645901829005, val_loss: 0.7327694700212236\n",
      "epoch: 10, iter: 31500, train_loss: 0.04722037598490715, val_loss: 0.7516106482903668\n",
      "epoch: 10, iter: 31550, train_loss: 0.0515876751486212, val_loss: 0.7349332488456349\n",
      "epoch: 10, iter: 31600, train_loss: 0.06410349983721972, val_loss: 0.7549990508586738\n",
      "epoch: 10, iter: 31650, train_loss: 0.0773956236988306, val_loss: 0.7652844492417232\n",
      "epoch: 10, iter: 31700, train_loss: 0.06231054805219174, val_loss: 0.7291102099950146\n",
      "epoch: 10, iter: 31750, train_loss: 0.06134230088442564, val_loss: 0.7449138306888046\n",
      "epoch: 10, iter: 31800, train_loss: 0.07514572579413653, val_loss: 0.7445081151594781\n",
      "epoch: 10, iter: 31850, train_loss: 0.06780873648822308, val_loss: 0.7611244510693155\n",
      "epoch: 10, iter: 31900, train_loss: 0.08863451262935997, val_loss: 0.7704093756189772\n",
      "epoch: 10, iter: 31950, train_loss: 0.0853740176744759, val_loss: 0.7964657276489173\n",
      "epoch: 10, iter: 32000, train_loss: 0.0952950856462121, val_loss: 0.7316196444118099\n",
      "epoch: 10, iter: 32050, train_loss: 0.08829918697476387, val_loss: 0.7431944681770483\n",
      "epoch: 11, iter: 32100, train_loss: 0.05532380070537329, val_loss: 0.7760483096739289\n",
      "epoch: 11, iter: 32150, train_loss: 0.07218481765128672, val_loss: 0.7518598393649812\n",
      "epoch: 11, iter: 32200, train_loss: 0.05586759747937322, val_loss: 0.6994032193521026\n",
      "epoch: 11, iter: 32250, train_loss: 0.04012694600969553, val_loss: 0.7251469719751625\n",
      "epoch: 11, iter: 32300, train_loss: 0.054946732548996804, val_loss: 0.7814895082621058\n",
      "epoch: 11, iter: 32350, train_loss: 0.04355010147206485, val_loss: 0.7659464703433833\n",
      "epoch: 11, iter: 32400, train_loss: 0.06115440191701055, val_loss: 0.7387002007976459\n",
      "epoch: 11, iter: 32450, train_loss: 0.05095300009474158, val_loss: 0.8066896254279811\n",
      "epoch: 11, iter: 32500, train_loss: 0.05929654978215695, val_loss: 0.7936345767822994\n",
      "epoch: 11, iter: 32550, train_loss: 0.056951125524938105, val_loss: 0.7884197460997636\n",
      "epoch: 11, iter: 32600, train_loss: 0.053049711007624865, val_loss: 0.8365222969252593\n",
      "epoch: 11, iter: 32650, train_loss: 0.06811911893077195, val_loss: 0.7474138402635124\n",
      "epoch: 11, iter: 32700, train_loss: 0.06745362006127835, val_loss: 0.7621861774071007\n",
      "epoch: 11, iter: 32750, train_loss: 0.08589252885431051, val_loss: 0.7792683873966242\n",
      "epoch: 11, iter: 32800, train_loss: 0.082999488376081, val_loss: 0.7730892091799694\n",
      "epoch: 12, iter: 32850, train_loss: 0.006644608154892921, val_loss: 0.8861349760347111\n",
      "epoch: 12, iter: 32900, train_loss: 0.04705074285157025, val_loss: 0.7207711113106673\n",
      "epoch: 12, iter: 32950, train_loss: 0.03579431156627834, val_loss: 0.7578418410507737\n",
      "epoch: 12, iter: 33000, train_loss: 0.033189709931612014, val_loss: 0.761867208465649\n",
      "epoch: 12, iter: 33050, train_loss: 0.034526808196678756, val_loss: 0.7952449842812909\n",
      "epoch: 12, iter: 33100, train_loss: 0.03831615808419883, val_loss: 0.782806929034792\n",
      "epoch: 12, iter: 33150, train_loss: 0.046614817837253214, val_loss: 0.7848535673633502\n",
      "epoch: 12, iter: 33200, train_loss: 0.05463195882737636, val_loss: 0.8675299171049884\n",
      "epoch: 12, iter: 33250, train_loss: 0.06213625069707632, val_loss: 0.787813613179383\n",
      "epoch: 12, iter: 33300, train_loss: 0.05229863686487079, val_loss: 0.7591494232605976\n",
      "epoch: 12, iter: 33350, train_loss: 0.05617838319391012, val_loss: 0.7900280950555376\n",
      "epoch: 12, iter: 33400, train_loss: 0.05873190470039844, val_loss: 0.7843642718852706\n",
      "epoch: 12, iter: 33450, train_loss: 0.06915708998218179, val_loss: 0.7427409983174816\n",
      "epoch: 12, iter: 33500, train_loss: 0.06353656221181155, val_loss: 0.7868680122551645\n",
      "epoch: 12, iter: 33550, train_loss: 0.05336459739133716, val_loss: 0.8011870646173027\n",
      "epoch: 12, iter: 33600, train_loss: 0.05910306412726641, val_loss: 0.8125069974714024\n",
      "epoch: 13, iter: 33650, train_loss: 0.04834744367748499, val_loss: 0.8052417197424895\n",
      "epoch: 13, iter: 33700, train_loss: 0.0661872734874487, val_loss: 0.8085896491434923\n",
      "epoch: 13, iter: 33750, train_loss: 0.045508648408576845, val_loss: 0.7463256113088814\n",
      "epoch: 13, iter: 33800, train_loss: 0.051391938724555074, val_loss: 0.8357856397036534\n",
      "epoch: 13, iter: 33850, train_loss: 0.04290638504549861, val_loss: 0.84254297224959\n",
      "epoch: 13, iter: 33900, train_loss: 0.031850739512592555, val_loss: 0.8233859968033566\n",
      "epoch: 13, iter: 33950, train_loss: 0.039012975003570316, val_loss: 0.7984222293279732\n",
      "epoch: 13, iter: 34000, train_loss: 0.04386815612204373, val_loss: 0.804374944252573\n",
      "epoch: 13, iter: 34050, train_loss: 0.05709887983743101, val_loss: 0.8079275445194002\n",
      "epoch: 13, iter: 34100, train_loss: 0.0489997442625463, val_loss: 0.7788703358097441\n",
      "epoch: 13, iter: 34150, train_loss: 0.04144931592047214, val_loss: 0.7904108393533974\n",
      "epoch: 13, iter: 34200, train_loss: 0.04860957390628755, val_loss: 0.7883186694353249\n",
      "epoch: 13, iter: 34250, train_loss: 0.060508747957646845, val_loss: 0.8107255186624588\n",
      "epoch: 13, iter: 34300, train_loss: 0.05239650910720229, val_loss: 0.8034897531103936\n",
      "epoch: 13, iter: 34350, train_loss: 0.05913025092333555, val_loss: 0.7693915182997466\n",
      "epoch: 13, iter: 34400, train_loss: 0.06343157011084259, val_loss: 0.7747558073443213\n",
      "epoch: 14, iter: 34450, train_loss: 0.05451440814882517, val_loss: 0.8167964253266147\n",
      "epoch: 14, iter: 34500, train_loss: 0.045026570595800876, val_loss: 0.7595262493297552\n",
      "epoch: 14, iter: 34550, train_loss: 0.03705311258789152, val_loss: 0.7757100827375035\n",
      "epoch: 14, iter: 34600, train_loss: 0.04037139194086194, val_loss: 0.8307394676717224\n",
      "epoch: 14, iter: 34650, train_loss: 0.03778088721446693, val_loss: 0.8206966146352185\n",
      "epoch: 14, iter: 34700, train_loss: 0.03143521279096603, val_loss: 0.8836075678752486\n",
      "epoch: 14, iter: 34750, train_loss: 0.038280583480373026, val_loss: 0.7971274996069586\n",
      "epoch: 14, iter: 34800, train_loss: 0.044976182179525495, val_loss: 0.8483970696759072\n",
      "epoch: 14, iter: 34850, train_loss: 0.052667303113266825, val_loss: 0.862986530325595\n",
      "epoch: 14, iter: 34900, train_loss: 0.06000480988994241, val_loss: 0.8013801577554387\n",
      "epoch: 14, iter: 34950, train_loss: 0.04689751084893942, val_loss: 0.7891597341579996\n",
      "epoch: 14, iter: 35000, train_loss: 0.05761508991010487, val_loss: 0.8669890852490808\n",
      "epoch: 14, iter: 35050, train_loss: 0.05813846150413156, val_loss: 0.7963690792868852\n",
      "epoch: 14, iter: 35100, train_loss: 0.04710789563134313, val_loss: 0.8050447261067712\n",
      "epoch: 14, iter: 35150, train_loss: 0.047662045136094094, val_loss: 0.8236157160465885\n",
      "epoch: 15, iter: 35200, train_loss: 0.0037921941094100475, val_loss: 0.7655051025045905\n",
      "epoch: 15, iter: 35250, train_loss: 0.029957034294493496, val_loss: 0.7904878258942418\n",
      "epoch: 15, iter: 35300, train_loss: 0.035462231570854784, val_loss: 0.8245817335547915\n",
      "epoch: 15, iter: 35350, train_loss: 0.034650982320308686, val_loss: 0.7757061328383008\n",
      "epoch: 15, iter: 35400, train_loss: 0.021951376213692128, val_loss: 0.8010739871081273\n",
      "epoch: 15, iter: 35450, train_loss: 0.02866965756751597, val_loss: 0.8363468221798065\n",
      "epoch: 15, iter: 35500, train_loss: 0.033535581813193854, val_loss: 0.7870897984808418\n",
      "epoch: 15, iter: 35550, train_loss: 0.030590599104762077, val_loss: 0.8292305646998108\n",
      "epoch: 15, iter: 35600, train_loss: 0.04170198814943433, val_loss: 0.9141869679757744\n",
      "epoch: 15, iter: 35650, train_loss: 0.03915789150632918, val_loss: 0.8644158523173848\n",
      "epoch: 15, iter: 35700, train_loss: 0.033607331793755295, val_loss: 0.872503931687516\n",
      "epoch: 15, iter: 35750, train_loss: 0.04701464068610221, val_loss: 0.8702476468815166\n",
      "epoch: 15, iter: 35800, train_loss: 0.05470441611483693, val_loss: 0.8383444325559458\n",
      "epoch: 15, iter: 35850, train_loss: 0.054128091018646955, val_loss: 0.9023760877976752\n",
      "epoch: 15, iter: 35900, train_loss: 0.05048254393972457, val_loss: 0.8822047797737608\n",
      "epoch: 15, iter: 35950, train_loss: 0.06580663505010306, val_loss: 0.8350699898923278\n",
      "epoch: 16, iter: 36000, train_loss: 0.02658064170740545, val_loss: 0.8315092300533489\n",
      "epoch: 16, iter: 36050, train_loss: 0.03508418626151979, val_loss: 0.7890033763685044\n",
      "epoch: 16, iter: 36100, train_loss: 0.0305410333070904, val_loss: 0.8512203898399499\n",
      "epoch: 16, iter: 36150, train_loss: 0.030856959805823862, val_loss: 0.8308329156060128\n",
      "epoch: 16, iter: 36200, train_loss: 0.027073248052038253, val_loss: 0.8062913623774887\n",
      "epoch: 16, iter: 36250, train_loss: 0.0330892275692895, val_loss: 0.8513008830653634\n",
      "epoch: 16, iter: 36300, train_loss: 0.03533815247006714, val_loss: 0.8836160220537975\n",
      "epoch: 16, iter: 36350, train_loss: 0.03871087335050106, val_loss: 0.8927888765836217\n",
      "epoch: 16, iter: 36400, train_loss: 0.04055334402713925, val_loss: 0.9125172040265077\n",
      "epoch: 16, iter: 36450, train_loss: 0.037193948002532125, val_loss: 0.9230360708608749\n",
      "epoch: 16, iter: 36500, train_loss: 0.046504752077162266, val_loss: 0.9010771256723221\n",
      "epoch: 16, iter: 36550, train_loss: 0.037439837451092896, val_loss: 0.9209186473659648\n",
      "epoch: 16, iter: 36600, train_loss: 0.04109853187575936, val_loss: 0.8829620512807446\n",
      "epoch: 16, iter: 36650, train_loss: 0.04671929499134422, val_loss: 0.8474602769514558\n",
      "epoch: 16, iter: 36700, train_loss: 0.053839714187197386, val_loss: 0.8689749686011843\n",
      "epoch: 16, iter: 36750, train_loss: 0.04759266193956137, val_loss: 0.8792706002854997\n",
      "epoch: 17, iter: 36800, train_loss: 0.022858126587234438, val_loss: 0.8636650619613138\n",
      "epoch: 17, iter: 36850, train_loss: 0.02836517246440053, val_loss: 0.9004069733771549\n",
      "epoch: 17, iter: 36900, train_loss: 0.021737561956979335, val_loss: 0.8746018262615629\n",
      "epoch: 17, iter: 36950, train_loss: 0.0371551335696131, val_loss: 0.9086930829628258\n",
      "epoch: 17, iter: 37000, train_loss: 0.030696725971065462, val_loss: 0.8953829830998827\n",
      "epoch: 17, iter: 37050, train_loss: 0.034969019815325735, val_loss: 0.8774481622656439\n",
      "epoch: 17, iter: 37100, train_loss: 0.03617724255658686, val_loss: 0.8419961272531254\n",
      "epoch: 17, iter: 37150, train_loss: 0.038630425687879326, val_loss: 0.8483083570838734\n",
      "epoch: 17, iter: 37200, train_loss: 0.03163474985398352, val_loss: 0.8603547644463314\n",
      "epoch: 17, iter: 37250, train_loss: 0.04337867026217282, val_loss: 0.8683607435909806\n",
      "epoch: 17, iter: 37300, train_loss: 0.03617914376780391, val_loss: 0.8548764625362529\n",
      "epoch: 17, iter: 37350, train_loss: 0.03831088945269585, val_loss: 0.8403106392568843\n",
      "epoch: 17, iter: 37400, train_loss: 0.04266808305867016, val_loss: 0.9383242904760276\n",
      "epoch: 17, iter: 37450, train_loss: 0.038797848657704886, val_loss: 0.8820287713389487\n",
      "epoch: 17, iter: 37500, train_loss: 0.04213063470553607, val_loss: 0.8652984362309146\n",
      "epoch: 18, iter: 37550, train_loss: 0.007563518593087792, val_loss: 0.8469119941353038\n",
      "epoch: 18, iter: 37600, train_loss: 0.02325329342391342, val_loss: 0.8906292455970861\n",
      "epoch: 18, iter: 37650, train_loss: 0.024451210633851587, val_loss: 0.909910841162797\n",
      "epoch: 18, iter: 37700, train_loss: 0.02522334285546094, val_loss: 0.888202202737711\n",
      "epoch: 18, iter: 37750, train_loss: 0.02232443921966478, val_loss: 0.8722184221645829\n",
      "epoch: 18, iter: 37800, train_loss: 0.03628905097022653, val_loss: 0.8529354262693672\n",
      "epoch: 18, iter: 37850, train_loss: 0.03634008963592351, val_loss: 0.9037444604809877\n",
      "epoch: 18, iter: 37900, train_loss: 0.04009122667834163, val_loss: 0.9174514452742922\n",
      "epoch: 18, iter: 37950, train_loss: 0.03698204461950809, val_loss: 0.8898778958305432\n",
      "epoch: 18, iter: 38000, train_loss: 0.05000369331799447, val_loss: 0.907190325913156\n",
      "epoch: 18, iter: 38050, train_loss: 0.03927287496160716, val_loss: 0.9173775480431356\n",
      "epoch: 18, iter: 38100, train_loss: 0.03874480445869267, val_loss: 0.8992577080324198\n",
      "epoch: 18, iter: 38150, train_loss: 0.0477794695738703, val_loss: 0.930549042904453\n",
      "epoch: 18, iter: 38200, train_loss: 0.0361101134121418, val_loss: 0.9140495548772204\n",
      "epoch: 18, iter: 38250, train_loss: 0.035647291988134384, val_loss: 0.8903088465238073\n",
      "epoch: 18, iter: 38300, train_loss: 0.04428527631796896, val_loss: 1.014053103935187\n",
      "epoch: 19, iter: 38350, train_loss: 0.03478299544658512, val_loss: 0.924976371181239\n",
      "epoch: 19, iter: 38400, train_loss: 0.05168699928559363, val_loss: 0.9081336307297846\n",
      "epoch: 19, iter: 38450, train_loss: 0.03857272021472454, val_loss: 0.9012082858829741\n",
      "epoch: 19, iter: 38500, train_loss: 0.030687842001207173, val_loss: 0.9241312156627133\n",
      "epoch: 19, iter: 38550, train_loss: 0.03404364442452788, val_loss: 0.8832274217894123\n",
      "epoch: 19, iter: 38600, train_loss: 0.025348556777462363, val_loss: 0.8851715186788778\n",
      "epoch: 19, iter: 38650, train_loss: 0.020954840718768537, val_loss: 0.8824844299607976\n",
      "epoch: 19, iter: 38700, train_loss: 0.020407900302670895, val_loss: 0.8838017513607718\n",
      "epoch: 19, iter: 38750, train_loss: 0.028856627438217403, val_loss: 0.9264391182334559\n",
      "epoch: 19, iter: 38800, train_loss: 0.021491856956854464, val_loss: 0.9822614794703806\n",
      "epoch: 19, iter: 38850, train_loss: 0.04689791871234775, val_loss: 0.9486370777628225\n",
      "epoch: 19, iter: 38900, train_loss: 0.04976535171270371, val_loss: 0.8996383623712382\n",
      "epoch: 19, iter: 38950, train_loss: 0.05396929051727056, val_loss: 0.9050719594689691\n",
      "epoch: 19, iter: 39000, train_loss: 0.033033224605023864, val_loss: 0.9248355451473005\n",
      "epoch: 19, iter: 39050, train_loss: 0.04556039395742118, val_loss: 0.908133314293661\n",
      "epoch: 19, iter: 39100, train_loss: 0.038859659228473904, val_loss: 0.8625597685195838\n",
      "epoch: 20, iter: 39150, train_loss: 0.031682664155960084, val_loss: 0.88026830478079\n",
      "epoch: 20, iter: 39200, train_loss: 0.02254185514058918, val_loss: 0.8904610047484659\n",
      "epoch: 20, iter: 39250, train_loss: 0.01866562350653112, val_loss: 0.9733525934113059\n",
      "epoch: 20, iter: 39300, train_loss: 0.024370587011799217, val_loss: 0.9118072236799131\n",
      "epoch: 20, iter: 39350, train_loss: 0.019101378354243935, val_loss: 0.9053913918650074\n",
      "epoch: 20, iter: 39400, train_loss: 0.025595299294218422, val_loss: 0.8732232683972948\n",
      "epoch: 20, iter: 39450, train_loss: 0.028331987522542477, val_loss: 0.8844809668838598\n",
      "epoch: 20, iter: 39500, train_loss: 0.03124265165068209, val_loss: 0.9142144402121283\n",
      "epoch: 20, iter: 39550, train_loss: 0.02466909817419946, val_loss: 0.8894627260364545\n",
      "epoch: 20, iter: 39600, train_loss: 0.02728545996360481, val_loss: 0.9112471282292324\n",
      "epoch: 20, iter: 39650, train_loss: 0.033242736738175155, val_loss: 0.9247707948563205\n",
      "epoch: 20, iter: 39700, train_loss: 0.03538666401989758, val_loss: 0.9274096581966255\n",
      "epoch: 20, iter: 39750, train_loss: 0.031349413003772496, val_loss: 0.9315558744084304\n",
      "epoch: 20, iter: 39800, train_loss: 0.040603960291482506, val_loss: 0.9222017125149441\n",
      "epoch: 20, iter: 39850, train_loss: 0.039854377531446515, val_loss: 0.8987092490598654\n",
      "epoch: 21, iter: 39900, train_loss: 0.009039743083994835, val_loss: 0.9155776743676253\n",
      "epoch: 21, iter: 39950, train_loss: 0.021650763009674848, val_loss: 0.9237362698764559\n",
      "epoch: 21, iter: 40000, train_loss: 0.029743722996208817, val_loss: 0.9531920351040591\n",
      "epoch: 21, iter: 40050, train_loss: 0.021702840444631874, val_loss: 0.9354764276249393\n",
      "epoch: 21, iter: 40100, train_loss: 0.02065019397996366, val_loss: 0.9082082809915968\n",
      "epoch: 21, iter: 40150, train_loss: 0.0317645295150578, val_loss: 0.8881706831751356\n",
      "epoch: 21, iter: 40200, train_loss: 0.0254221284808591, val_loss: 0.9153604261624585\n",
      "epoch: 21, iter: 40250, train_loss: 0.030361158386804164, val_loss: 0.8680437340098581\n",
      "epoch: 21, iter: 40300, train_loss: 0.016197798729408533, val_loss: 0.9153405020760882\n",
      "epoch: 21, iter: 40350, train_loss: 0.024982187189161776, val_loss: 0.9195932011315777\n",
      "epoch: 21, iter: 40400, train_loss: 0.028702969988808037, val_loss: 0.8927146038811677\n",
      "epoch: 21, iter: 40450, train_loss: 0.030243372125551105, val_loss: 0.9630059958643215\n",
      "epoch: 21, iter: 40500, train_loss: 0.0226185090187937, val_loss: 0.9644895468358021\n",
      "epoch: 21, iter: 40550, train_loss: 0.023003524425439535, val_loss: 0.9856362141621341\n",
      "epoch: 21, iter: 40600, train_loss: 0.035704287667758766, val_loss: 0.9471891364853853\n",
      "epoch: 21, iter: 40650, train_loss: 0.039989072028547526, val_loss: 0.9420394154301115\n",
      "epoch: 22, iter: 40700, train_loss: 0.01430511832004413, val_loss: 0.8871339926863931\n",
      "epoch: 22, iter: 40750, train_loss: 0.021753958803601564, val_loss: 0.9580980144488583\n",
      "epoch: 22, iter: 40800, train_loss: 0.03211108630988747, val_loss: 0.9347719402070258\n",
      "epoch: 22, iter: 40850, train_loss: 0.02495926581788808, val_loss: 0.9245747211062985\n",
      "epoch: 22, iter: 40900, train_loss: 0.026199265285395085, val_loss: 0.9578744931395646\n",
      "epoch: 22, iter: 40950, train_loss: 0.031431261976249514, val_loss: 0.9179409829674253\n",
      "epoch: 22, iter: 41000, train_loss: 0.026008512885309757, val_loss: 0.9357737410979666\n",
      "epoch: 22, iter: 41050, train_loss: 0.030473736156709494, val_loss: 0.9486552598370108\n",
      "epoch: 22, iter: 41100, train_loss: 0.03237748465500772, val_loss: 0.9165293136789541\n",
      "epoch: 22, iter: 41150, train_loss: 0.026819843356497584, val_loss: 0.937047679617906\n",
      "epoch: 22, iter: 41200, train_loss: 0.01983193733263761, val_loss: 1.0100342960209603\n",
      "epoch: 22, iter: 41250, train_loss: 0.030556792081333696, val_loss: 0.9316099469259287\n",
      "epoch: 22, iter: 41300, train_loss: 0.032961134416982535, val_loss: 0.9354768049944738\n",
      "epoch: 22, iter: 41350, train_loss: 0.03371267112670466, val_loss: 0.9215827973405267\n",
      "epoch: 22, iter: 41400, train_loss: 0.030327425352297724, val_loss: 0.9830220387240124\n",
      "epoch: 23, iter: 41450, train_loss: 0.0009311424847692251, val_loss: 1.1153757498142824\n",
      "epoch: 23, iter: 41500, train_loss: 0.053326476984657346, val_loss: 0.9850639815732931\n",
      "epoch: 23, iter: 41550, train_loss: 0.04169495870824903, val_loss: 0.9502669373515306\n",
      "epoch: 23, iter: 41600, train_loss: 0.030409904499538242, val_loss: 0.9140294664035178\n",
      "epoch: 23, iter: 41650, train_loss: 0.026116181118413805, val_loss: 0.9700231855841959\n",
      "epoch: 23, iter: 41700, train_loss: 0.026466402402147652, val_loss: 1.0083053551471917\n",
      "epoch: 23, iter: 41750, train_loss: 0.03404587948461994, val_loss: 0.9187859566348373\n",
      "epoch: 23, iter: 41800, train_loss: 0.024103523339144884, val_loss: 0.9184223464719808\n",
      "epoch: 23, iter: 41850, train_loss: 0.032134605566971, val_loss: 0.9215227641687271\n",
      "epoch: 23, iter: 41900, train_loss: 0.0254474466945976, val_loss: 0.8981752266549761\n",
      "epoch: 23, iter: 41950, train_loss: 0.021119524042587726, val_loss: 0.9341487379115858\n",
      "epoch: 23, iter: 42000, train_loss: 0.026517462115734816, val_loss: 0.9419033593338006\n",
      "epoch: 23, iter: 42050, train_loss: 0.018107946156524123, val_loss: 0.9377538704188766\n",
      "epoch: 23, iter: 42100, train_loss: 0.02412691560573876, val_loss: 0.9685131561983923\n",
      "epoch: 23, iter: 42150, train_loss: 0.023513011089526116, val_loss: 0.9993377009015174\n",
      "epoch: 23, iter: 42200, train_loss: 0.028115088783670215, val_loss: 0.9485007436222331\n",
      "epoch: 24, iter: 42250, train_loss: 0.010939123975113034, val_loss: 0.958865634954659\n",
      "epoch: 24, iter: 42300, train_loss: 0.02435164249036461, val_loss: 1.0327072692145207\n",
      "epoch: 24, iter: 42350, train_loss: 0.03177344169467688, val_loss: 0.99226776942326\n",
      "epoch: 24, iter: 42400, train_loss: 0.02523506833706051, val_loss: 0.9770170540376834\n",
      "epoch: 24, iter: 42450, train_loss: 0.032015523482114075, val_loss: 1.0010206583578876\n",
      "epoch: 24, iter: 42500, train_loss: 0.029170569516718387, val_loss: 1.0170013255374446\n",
      "epoch: 24, iter: 42550, train_loss: 0.026785275212023407, val_loss: 1.0134318953107118\n",
      "epoch: 24, iter: 42600, train_loss: 0.03250586966983974, val_loss: 0.9117387941308842\n",
      "epoch: 24, iter: 42650, train_loss: 0.03200736289843917, val_loss: 0.9196916007122417\n",
      "epoch: 24, iter: 42700, train_loss: 0.024170652641914786, val_loss: 0.9071901499465772\n",
      "epoch: 24, iter: 42750, train_loss: 0.01863361428491771, val_loss: 0.9572846919867644\n",
      "epoch: 24, iter: 42800, train_loss: 0.0227464651921764, val_loss: 0.8924779369952572\n",
      "epoch: 24, iter: 42850, train_loss: 0.02256496838759631, val_loss: 0.8956179226849489\n",
      "epoch: 24, iter: 42900, train_loss: 0.04034554232377559, val_loss: 0.8914866279454747\n",
      "epoch: 24, iter: 42950, train_loss: 0.032316397936083374, val_loss: 0.9460617450012523\n",
      "epoch: 24, iter: 43000, train_loss: 0.030331903900951147, val_loss: 1.0125682348278677\n",
      "epoch: 25, iter: 43050, train_loss: 0.01652210936881602, val_loss: 0.9846906467418003\n",
      "epoch: 25, iter: 43100, train_loss: 0.02248160701710731, val_loss: 0.9339436671346616\n",
      "epoch: 25, iter: 43150, train_loss: 0.022704893068876117, val_loss: 0.9819293934258686\n",
      "epoch: 25, iter: 43200, train_loss: 0.028340762238949536, val_loss: 0.9854948097353529\n",
      "epoch: 25, iter: 43250, train_loss: 0.019038228986319156, val_loss: 0.9849659985607597\n",
      "epoch: 25, iter: 43300, train_loss: 0.02519850046839565, val_loss: 0.9806510807981916\n",
      "epoch: 25, iter: 43350, train_loss: 0.026559716798365118, val_loss: 1.0064942944960988\n",
      "epoch: 25, iter: 43400, train_loss: 0.04524057778995484, val_loss: 0.8988155668518346\n",
      "epoch: 25, iter: 43450, train_loss: 0.019069864731281996, val_loss: 0.9149368980507941\n",
      "epoch: 25, iter: 43500, train_loss: 0.04081132552586496, val_loss: 0.988255213969832\n",
      "epoch: 25, iter: 43550, train_loss: 0.025214883694425226, val_loss: 0.9190300266454174\n",
      "epoch: 25, iter: 43600, train_loss: 0.025643094712868332, val_loss: 0.9187459814700352\n",
      "epoch: 25, iter: 43650, train_loss: 0.022265944750979542, val_loss: 1.0355031154337961\n",
      "epoch: 25, iter: 43700, train_loss: 0.026500210913363843, val_loss: 0.9706091280955418\n",
      "epoch: 25, iter: 43750, train_loss: 0.0232304308260791, val_loss: 0.9106663218729055\n",
      "epoch: 26, iter: 43800, train_loss: 0.0018826397880911828, val_loss: 0.926487069410883\n",
      "epoch: 26, iter: 43850, train_loss: 0.023562175903934987, val_loss: 0.9812837831533638\n",
      "epoch: 26, iter: 43900, train_loss: 0.016476066091563553, val_loss: 0.9632655084133148\n",
      "epoch: 26, iter: 43950, train_loss: 0.020612410586327314, val_loss: 0.9189463411546817\n",
      "epoch: 26, iter: 44000, train_loss: 0.023604880080092698, val_loss: 0.9368939469954011\n",
      "epoch: 26, iter: 44050, train_loss: 0.023908048872835933, val_loss: 0.8918075266347569\n",
      "epoch: 26, iter: 44100, train_loss: 0.016312945189420135, val_loss: 0.9016926673946867\n",
      "epoch: 26, iter: 44150, train_loss: 0.022941473005339504, val_loss: 0.9378181410253428\n",
      "epoch: 26, iter: 44200, train_loss: 0.0149741405621171, val_loss: 0.953185831285586\n",
      "epoch: 26, iter: 44250, train_loss: 0.018394132610410452, val_loss: 0.9604941879867748\n",
      "epoch: 26, iter: 44300, train_loss: 0.017764295553788542, val_loss: 0.9143052944901643\n",
      "epoch: 26, iter: 44350, train_loss: 0.0208444831892848, val_loss: 0.946738187769416\n",
      "epoch: 26, iter: 44400, train_loss: 0.027388411639258266, val_loss: 0.9362616848414111\n",
      "epoch: 26, iter: 44450, train_loss: 0.022949866771232338, val_loss: 0.9997710950055699\n",
      "epoch: 26, iter: 44500, train_loss: 0.03358968890272081, val_loss: 0.9496892570120514\n",
      "epoch: 26, iter: 44550, train_loss: 0.03629504091572017, val_loss: 1.0436708743025542\n",
      "epoch: 27, iter: 44600, train_loss: 0.016528134886175393, val_loss: 0.9634365834248294\n",
      "epoch: 27, iter: 44650, train_loss: 0.02561219851486385, val_loss: 0.917122550545984\n",
      "epoch: 27, iter: 44700, train_loss: 0.0263480956107378, val_loss: 0.9428645724513728\n",
      "epoch: 27, iter: 44750, train_loss: 0.02481662394478917, val_loss: 0.9373725928888199\n",
      "epoch: 27, iter: 44800, train_loss: 0.02324259149376303, val_loss: 0.9429040252213265\n",
      "epoch: 27, iter: 44850, train_loss: 0.021400287682190537, val_loss: 1.001810855404207\n",
      "epoch: 27, iter: 44900, train_loss: 0.03359400891233236, val_loss: 0.9922611172411852\n",
      "epoch: 27, iter: 44950, train_loss: 0.03213911439292133, val_loss: 0.9365196628555371\n",
      "epoch: 27, iter: 45000, train_loss: 0.022980052730999886, val_loss: 0.9314898742706912\n",
      "epoch: 27, iter: 45050, train_loss: 0.0306125652580522, val_loss: 0.9088192071504654\n",
      "epoch: 27, iter: 45100, train_loss: 0.02153614642797038, val_loss: 0.8918669972639934\n",
      "epoch: 27, iter: 45150, train_loss: 0.02095794302877039, val_loss: 0.9141599966841898\n",
      "epoch: 27, iter: 45200, train_loss: 0.014381223323289305, val_loss: 0.9456958075997176\n",
      "epoch: 27, iter: 45250, train_loss: 0.022705034504178913, val_loss: 0.9825629768477884\n",
      "epoch: 27, iter: 45300, train_loss: 0.01930520482128486, val_loss: 1.044158423971978\n",
      "epoch: 27, iter: 45350, train_loss: 0.027322275154292582, val_loss: 0.9914577529308902\n",
      "epoch: 28, iter: 45400, train_loss: 0.02852438694331795, val_loss: 0.9169410825914638\n",
      "epoch: 28, iter: 45450, train_loss: 0.015340496050193907, val_loss: 0.9494374853790186\n",
      "epoch: 28, iter: 45500, train_loss: 0.029016344398260115, val_loss: 0.9094134497035081\n",
      "epoch: 28, iter: 45550, train_loss: 0.02085342104546726, val_loss: 0.9207839217914897\n",
      "epoch: 28, iter: 45600, train_loss: 0.018494896828196942, val_loss: 0.9414383396980869\n",
      "epoch: 28, iter: 45650, train_loss: 0.012643496631644666, val_loss: 0.9067755079573128\n",
      "epoch: 28, iter: 45700, train_loss: 0.015424017882905901, val_loss: 0.9748482729788799\n",
      "epoch: 28, iter: 45750, train_loss: 0.017289222697727383, val_loss: 0.9945336183544936\n",
      "epoch: 28, iter: 45800, train_loss: 0.0175016336562112, val_loss: 0.9903629653772731\n",
      "epoch: 28, iter: 45850, train_loss: 0.02306500597158447, val_loss: 0.9425730243989616\n",
      "epoch: 28, iter: 45900, train_loss: 0.020111608661245554, val_loss: 0.9584696157153245\n",
      "epoch: 28, iter: 45950, train_loss: 0.02836399229709059, val_loss: 1.0875136217304096\n",
      "epoch: 28, iter: 46000, train_loss: 0.059351934609003364, val_loss: 1.0991347358105288\n",
      "epoch: 28, iter: 46050, train_loss: 0.05544233973370865, val_loss: 1.0405606304763988\n",
      "epoch: 28, iter: 46100, train_loss: 0.058609425500035284, val_loss: 1.0018948616495558\n",
      "epoch: 29, iter: 46150, train_loss: 0.004388430416584015, val_loss: 0.9692600107496712\n",
      "epoch: 29, iter: 46200, train_loss: 0.026075867167674006, val_loss: 0.9410011205513766\n",
      "epoch: 29, iter: 46250, train_loss: 0.022742511625401675, val_loss: 0.9658134383190969\n",
      "epoch: 29, iter: 46300, train_loss: 0.021052136037033053, val_loss: 0.92664079548447\n",
      "epoch: 29, iter: 46350, train_loss: 0.013717682249844074, val_loss: 1.0174083083298555\n",
      "epoch: 29, iter: 46400, train_loss: 0.015482742013409734, val_loss: 1.0050943421710068\n",
      "epoch: 29, iter: 46450, train_loss: 0.018830923857167364, val_loss: 1.0647516151902023\n",
      "epoch: 29, iter: 46500, train_loss: 0.023771157003939152, val_loss: 1.004479230589168\n",
      "epoch: 29, iter: 46550, train_loss: 0.02736711425706744, val_loss: 0.9719486464360717\n",
      "epoch: 29, iter: 46600, train_loss: 0.02732167952693999, val_loss: 0.9853805166900538\n",
      "epoch: 29, iter: 46650, train_loss: 0.031421625989023594, val_loss: 0.9986598619799705\n",
      "epoch: 29, iter: 46700, train_loss: 0.030324701378121974, val_loss: 0.9873822787005431\n",
      "epoch: 29, iter: 46750, train_loss: 0.020521770087070762, val_loss: 1.036683036453405\n",
      "epoch: 29, iter: 46800, train_loss: 0.01449889603536576, val_loss: 1.0210525365012466\n",
      "epoch: 29, iter: 46850, train_loss: 0.02008616671897471, val_loss: 1.0008038219752584\n",
      "epoch: 29, iter: 46900, train_loss: 0.04063690407434478, val_loss: 0.9969544404061736\n",
      "best loss:  0.5344467559817491\n",
      "Born Again...\n",
      "epoch: 0, iter: 46950, train_loss: 1.4313975381851196, val_loss: 2.3387106892409597\n",
      "epoch: 0, iter: 47000, train_loss: 1.7428173971176149, val_loss: 2.034115205904481\n",
      "epoch: 0, iter: 47050, train_loss: 1.6253186464309692, val_loss: 2.0051949009014542\n",
      "epoch: 0, iter: 47100, train_loss: 1.5798665165901185, val_loss: 1.9416842885837433\n",
      "epoch: 0, iter: 47150, train_loss: 1.5294629049301147, val_loss: 1.8800759444570845\n",
      "epoch: 0, iter: 47200, train_loss: 1.5039572596549988, val_loss: 1.8300739260995464\n",
      "epoch: 0, iter: 47250, train_loss: 1.4771959757804871, val_loss: 1.817371725276777\n",
      "epoch: 0, iter: 47300, train_loss: 1.4156238222122193, val_loss: 1.703808983420111\n",
      "epoch: 0, iter: 47350, train_loss: 1.3923591709136962, val_loss: 1.6822428483112601\n",
      "epoch: 0, iter: 47400, train_loss: 1.3408578109741212, val_loss: 1.6415721823455423\n",
      "epoch: 0, iter: 47450, train_loss: 1.2928495240211486, val_loss: 1.5952988559273398\n",
      "epoch: 0, iter: 47500, train_loss: 1.2613239622116088, val_loss: 1.5671892507820373\n",
      "epoch: 0, iter: 47550, train_loss: 1.24618177652359, val_loss: 1.5211611849487208\n",
      "epoch: 0, iter: 47600, train_loss: 1.199424821138382, val_loss: 1.4786594794813994\n",
      "epoch: 0, iter: 47650, train_loss: 1.1983671593666076, val_loss: 1.4470309330399629\n",
      "epoch: 0, iter: 47700, train_loss: 1.1494424188137053, val_loss: 1.44731553572758\n",
      "epoch: 1, iter: 47750, train_loss: 1.1044912648200989, val_loss: 1.381419572860572\n",
      "epoch: 1, iter: 47800, train_loss: 1.0754290676116944, val_loss: 1.3213178086432682\n",
      "epoch: 1, iter: 47850, train_loss: 1.0669895780086518, val_loss: 1.3093238469142063\n",
      "epoch: 1, iter: 47900, train_loss: 1.0341135990619659, val_loss: 1.2658569102833985\n",
      "epoch: 1, iter: 47950, train_loss: 1.015099095106125, val_loss: 1.1911492640045798\n",
      "epoch: 1, iter: 48000, train_loss: 0.9823126637935639, val_loss: 1.163398530452874\n",
      "epoch: 1, iter: 48050, train_loss: 0.9534204733371735, val_loss: 1.1985725054315701\n",
      "epoch: 1, iter: 48100, train_loss: 0.9564592778682709, val_loss: 1.179508031933171\n",
      "epoch: 1, iter: 48150, train_loss: 0.9357324504852295, val_loss: 1.1697242347298153\n",
      "epoch: 1, iter: 48200, train_loss: 0.9039483821392059, val_loss: 1.1023909833021224\n",
      "epoch: 1, iter: 48250, train_loss: 0.8872675144672394, val_loss: 1.0827917600892911\n",
      "epoch: 1, iter: 48300, train_loss: 0.900304993391037, val_loss: 1.1802692709455065\n",
      "epoch: 1, iter: 48350, train_loss: 0.8849730062484741, val_loss: 1.0668845169103829\n",
      "epoch: 1, iter: 48400, train_loss: 0.8513815009593964, val_loss: 1.0221986527655536\n",
      "epoch: 1, iter: 48450, train_loss: 0.8334207022190094, val_loss: 1.0338895271538169\n",
      "epoch: 2, iter: 48500, train_loss: 0.25528448581695556, val_loss: 1.0261779712263945\n",
      "epoch: 2, iter: 48550, train_loss: 0.8047914803028107, val_loss: 1.005733575790551\n",
      "epoch: 2, iter: 48600, train_loss: 0.7835002529621125, val_loss: 0.9837193063869598\n",
      "epoch: 2, iter: 48650, train_loss: 0.7802307212352753, val_loss: 1.0085741456147213\n",
      "epoch: 2, iter: 48700, train_loss: 0.7637289011478424, val_loss: 0.9586787774304676\n",
      "epoch: 2, iter: 48750, train_loss: 0.7300366771221161, val_loss: 0.9519226019549522\n",
      "epoch: 2, iter: 48800, train_loss: 0.7731684410572052, val_loss: 0.9202427385718959\n",
      "epoch: 2, iter: 48850, train_loss: 0.7638392913341522, val_loss: 0.9995218143341648\n",
      "epoch: 2, iter: 48900, train_loss: 0.7485654067993164, val_loss: 0.9135888211286751\n",
      "epoch: 2, iter: 48950, train_loss: 0.6741993844509124, val_loss: 0.9175557547314152\n",
      "epoch: 2, iter: 49000, train_loss: 0.679727863073349, val_loss: 0.9045086802950331\n",
      "epoch: 2, iter: 49050, train_loss: 0.6935632169246674, val_loss: 0.9116406034512125\n",
      "epoch: 2, iter: 49100, train_loss: 0.6892379403114319, val_loss: 0.9087415732395877\n",
      "epoch: 2, iter: 49150, train_loss: 0.6803321290016174, val_loss: 0.8609468701538766\n",
      "epoch: 2, iter: 49200, train_loss: 0.6590668261051178, val_loss: 0.8111739534481316\n",
      "epoch: 2, iter: 49250, train_loss: 0.64490205347538, val_loss: 0.8061134103377154\n",
      "epoch: 3, iter: 49300, train_loss: 0.42237237572669983, val_loss: 0.8423087513370878\n",
      "epoch: 3, iter: 49350, train_loss: 0.6356000864505768, val_loss: 0.7976543071922982\n",
      "epoch: 3, iter: 49400, train_loss: 0.5500061213970184, val_loss: 0.7873584320590754\n",
      "epoch: 3, iter: 49450, train_loss: 0.575659891963005, val_loss: 0.8106688934906273\n",
      "epoch: 3, iter: 49500, train_loss: 0.5856827628612519, val_loss: 0.7907688792344112\n",
      "epoch: 3, iter: 49550, train_loss: 0.5752246516942978, val_loss: 0.7713466952940461\n",
      "epoch: 3, iter: 49600, train_loss: 0.5540920782089234, val_loss: 0.784373809008082\n",
      "epoch: 3, iter: 49650, train_loss: 0.5268303775787353, val_loss: 0.7659684571490926\n",
      "epoch: 3, iter: 49700, train_loss: 0.5626999503374099, val_loss: 0.72955090965435\n",
      "epoch: 3, iter: 49750, train_loss: 0.5717684417963028, val_loss: 0.7199019127210994\n",
      "epoch: 3, iter: 49800, train_loss: 0.5427688705921173, val_loss: 0.7231972082784981\n",
      "epoch: 3, iter: 49850, train_loss: 0.5202371484041214, val_loss: 0.7215693906234328\n",
      "epoch: 3, iter: 49900, train_loss: 0.5515924924612046, val_loss: 0.7606288069372724\n",
      "epoch: 3, iter: 49950, train_loss: 0.5547403639554978, val_loss: 0.7256406762038067\n",
      "epoch: 3, iter: 50000, train_loss: 0.5303061401844025, val_loss: 0.7148092337854349\n",
      "epoch: 4, iter: 50050, train_loss: 0.0199323433637619, val_loss: 0.6796128106345037\n",
      "epoch: 4, iter: 50100, train_loss: 0.4865356332063675, val_loss: 0.6946532695916048\n",
      "epoch: 4, iter: 50150, train_loss: 0.44356272637844085, val_loss: 0.708458376538222\n",
      "epoch: 4, iter: 50200, train_loss: 0.454705890417099, val_loss: 0.6882845913148989\n",
      "epoch: 4, iter: 50250, train_loss: 0.46411949038505557, val_loss: 0.6757252886416806\n",
      "epoch: 4, iter: 50300, train_loss: 0.44550516963005066, val_loss: 0.634624722277283\n",
      "epoch: 4, iter: 50350, train_loss: 0.4252003002166748, val_loss: 0.6622961892443857\n",
      "epoch: 4, iter: 50400, train_loss: 0.46154331624507905, val_loss: 0.6526072964926434\n",
      "epoch: 4, iter: 50450, train_loss: 0.4236026281118393, val_loss: 0.6528790557080772\n",
      "epoch: 4, iter: 50500, train_loss: 0.450020267367363, val_loss: 0.6171115727940942\n",
      "epoch: 4, iter: 50550, train_loss: 0.43473624587059023, val_loss: 0.6343733015333771\n",
      "epoch: 4, iter: 50600, train_loss: 0.43217911779880525, val_loss: 0.6187163416747075\n",
      "epoch: 4, iter: 50650, train_loss: 0.4280890202522278, val_loss: 0.604674906867325\n",
      "epoch: 4, iter: 50700, train_loss: 0.4327764421701431, val_loss: 0.6017428871932303\n",
      "epoch: 4, iter: 50750, train_loss: 0.42585390686988833, val_loss: 0.6131790335390978\n",
      "epoch: 4, iter: 50800, train_loss: 0.4151135045289993, val_loss: 0.6421109082972168\n",
      "epoch: 5, iter: 50850, train_loss: 0.1297648701071739, val_loss: 0.6038912841279036\n",
      "epoch: 5, iter: 50900, train_loss: 0.31011331170797346, val_loss: 0.6067690565517754\n",
      "epoch: 5, iter: 50950, train_loss: 0.31923663794994356, val_loss: 0.581142463691675\n",
      "epoch: 5, iter: 51000, train_loss: 0.3407047083973885, val_loss: 0.6005175406006491\n",
      "epoch: 5, iter: 51050, train_loss: 0.34330431669950484, val_loss: 0.6492637851435668\n",
      "epoch: 5, iter: 51100, train_loss: 0.32728530675172807, val_loss: 0.615050177095802\n",
      "epoch: 5, iter: 51150, train_loss: 0.3429157018661499, val_loss: 0.6220278927854671\n",
      "epoch: 5, iter: 51200, train_loss: 0.3421088734269142, val_loss: 0.5947304097520318\n",
      "epoch: 5, iter: 51250, train_loss: 0.3246213975548744, val_loss: 0.6242544003732645\n",
      "epoch: 5, iter: 51300, train_loss: 0.34827222347259523, val_loss: 0.626635372259055\n",
      "epoch: 5, iter: 51350, train_loss: 0.3476600667834282, val_loss: 0.5971848669515294\n",
      "epoch: 5, iter: 51400, train_loss: 0.34184385001659395, val_loss: 0.5969607287151798\n",
      "epoch: 5, iter: 51450, train_loss: 0.3266696962714195, val_loss: 0.5781222144319753\n",
      "epoch: 5, iter: 51500, train_loss: 0.37297067523002625, val_loss: 0.5769434035963313\n",
      "epoch: 5, iter: 51550, train_loss: 0.33389682725071906, val_loss: 0.5739726737426345\n",
      "epoch: 5, iter: 51600, train_loss: 0.3519161731004715, val_loss: 0.5628298413791474\n",
      "epoch: 6, iter: 51650, train_loss: 0.18038348913192748, val_loss: 0.5697905712636413\n",
      "epoch: 6, iter: 51700, train_loss: 0.22948394238948822, val_loss: 0.6530595195900862\n",
      "epoch: 6, iter: 51750, train_loss: 0.24505730867385864, val_loss: 0.5935221046778807\n",
      "epoch: 6, iter: 51800, train_loss: 0.2126740325987339, val_loss: 0.6165522706166954\n",
      "epoch: 6, iter: 51850, train_loss: 0.23844199508428573, val_loss: 0.5927152090771183\n",
      "epoch: 6, iter: 51900, train_loss: 0.25850638911128043, val_loss: 0.6376273859838012\n",
      "epoch: 6, iter: 51950, train_loss: 0.24042880326509475, val_loss: 0.5843962102558962\n",
      "epoch: 6, iter: 52000, train_loss: 0.24007907316088675, val_loss: 0.6206236216862491\n",
      "epoch: 6, iter: 52050, train_loss: 0.2492060825228691, val_loss: 0.6104765993774317\n",
      "epoch: 6, iter: 52100, train_loss: 0.26857542246580124, val_loss: 0.5832059464067411\n",
      "epoch: 6, iter: 52150, train_loss: 0.2556652340292931, val_loss: 0.6187812289234939\n",
      "epoch: 6, iter: 52200, train_loss: 0.2499038062989712, val_loss: 0.5969863562447251\n",
      "epoch: 6, iter: 52250, train_loss: 0.24697485893964768, val_loss: 0.5888899714703772\n",
      "epoch: 6, iter: 52300, train_loss: 0.2635134986042976, val_loss: 0.5923683900552191\n",
      "epoch: 6, iter: 52350, train_loss: 0.27210049867630004, val_loss: 0.5634504072605424\n",
      "epoch: 7, iter: 52400, train_loss: 0.024874112904071807, val_loss: 0.613934258366846\n",
      "epoch: 7, iter: 52450, train_loss: 0.1624156679958105, val_loss: 0.6043801888538773\n",
      "epoch: 7, iter: 52500, train_loss: 0.15532834462821485, val_loss: 0.5906788909890849\n",
      "epoch: 7, iter: 52550, train_loss: 0.16334191508591175, val_loss: 0.5846916217902663\n",
      "epoch: 7, iter: 52600, train_loss: 0.15412512198090553, val_loss: 0.6398286286053384\n",
      "epoch: 7, iter: 52650, train_loss: 0.15465969622135162, val_loss: 0.6527268039952417\n",
      "epoch: 7, iter: 52700, train_loss: 0.1876683646440506, val_loss: 0.6525790801473484\n",
      "epoch: 7, iter: 52750, train_loss: 0.19996248438954353, val_loss: 0.6094891765884533\n",
      "epoch: 7, iter: 52800, train_loss: 0.18466855272650717, val_loss: 0.6208934717497249\n",
      "epoch: 7, iter: 52850, train_loss: 0.20889876440167426, val_loss: 0.5870668936497087\n",
      "epoch: 7, iter: 52900, train_loss: 0.1791565378010273, val_loss: 0.6202868925538033\n",
      "epoch: 7, iter: 52950, train_loss: 0.17552988588809967, val_loss: 0.6322427021849687\n",
      "epoch: 7, iter: 53000, train_loss: 0.1669136293232441, val_loss: 0.6663014536640447\n",
      "epoch: 7, iter: 53050, train_loss: 0.1913529323041439, val_loss: 0.6017323084128131\n",
      "epoch: 7, iter: 53100, train_loss: 0.1951894111931324, val_loss: 0.6215809173644729\n",
      "epoch: 7, iter: 53150, train_loss: 0.21451400935649872, val_loss: 0.6402120872098169\n",
      "epoch: 8, iter: 53200, train_loss: 0.06985551491379738, val_loss: 0.715301397404853\n",
      "epoch: 8, iter: 53250, train_loss: 0.13290663033723832, val_loss: 0.639962650218587\n",
      "epoch: 8, iter: 53300, train_loss: 0.09534525413066149, val_loss: 0.6967859577601123\n",
      "epoch: 8, iter: 53350, train_loss: 0.1134190422296524, val_loss: 0.6764228408503684\n",
      "epoch: 8, iter: 53400, train_loss: 0.13123059019446373, val_loss: 0.6491578931261779\n",
      "epoch: 8, iter: 53450, train_loss: 0.10080347247421742, val_loss: 0.6915129557916313\n",
      "epoch: 8, iter: 53500, train_loss: 0.10952716680243611, val_loss: 0.7234099793965649\n",
      "epoch: 8, iter: 53550, train_loss: 0.12950012631714344, val_loss: 0.6665638667193188\n",
      "epoch: 8, iter: 53600, train_loss: 0.14273624055087566, val_loss: 0.6677340450370388\n",
      "epoch: 8, iter: 53650, train_loss: 0.1418233944475651, val_loss: 0.6718609348224227\n",
      "epoch: 8, iter: 53700, train_loss: 0.14626157775521278, val_loss: 0.6241901535896739\n",
      "epoch: 8, iter: 53750, train_loss: 0.119644156396389, val_loss: 0.7032013757593313\n",
      "epoch: 8, iter: 53800, train_loss: 0.13842644445598126, val_loss: 0.6764342059755022\n",
      "epoch: 8, iter: 53850, train_loss: 0.14585404798388482, val_loss: 0.678741824854711\n",
      "epoch: 8, iter: 53900, train_loss: 0.13454941373318433, val_loss: 0.7003841508345999\n",
      "epoch: 8, iter: 53950, train_loss: 0.1476159729063511, val_loss: 0.6514496228117852\n",
      "epoch: 9, iter: 54000, train_loss: 0.06866309167817235, val_loss: 0.6825013291683926\n",
      "epoch: 9, iter: 54050, train_loss: 0.07193130547180772, val_loss: 0.6906953251855389\n",
      "epoch: 9, iter: 54100, train_loss: 0.06754548095166683, val_loss: 0.7321223702020706\n",
      "epoch: 9, iter: 54150, train_loss: 0.07901079649105668, val_loss: 0.7335552892107873\n",
      "epoch: 9, iter: 54200, train_loss: 0.08239701949059963, val_loss: 0.7510004839889562\n",
      "epoch: 9, iter: 54250, train_loss: 0.09148819060996174, val_loss: 0.6973714976553704\n",
      "epoch: 9, iter: 54300, train_loss: 0.08427415780723095, val_loss: 0.7693751805527195\n",
      "epoch: 9, iter: 54350, train_loss: 0.08768484693020583, val_loss: 0.7505701969193804\n",
      "epoch: 9, iter: 54400, train_loss: 0.09838684312999249, val_loss: 0.7273921083872485\n",
      "epoch: 9, iter: 54450, train_loss: 0.08792005559429526, val_loss: 0.7167407614979774\n",
      "epoch: 9, iter: 54500, train_loss: 0.08803325854241847, val_loss: 0.7304228392376262\n",
      "epoch: 9, iter: 54550, train_loss: 0.10940621547400951, val_loss: 0.7009174578888401\n",
      "epoch: 9, iter: 54600, train_loss: 0.09493199963122606, val_loss: 0.7148467774034306\n",
      "epoch: 9, iter: 54650, train_loss: 0.1119590549916029, val_loss: 0.6830944158848683\n",
      "epoch: 9, iter: 54700, train_loss: 0.10969137877225876, val_loss: 0.7104844640774332\n",
      "epoch: 10, iter: 54750, train_loss: 0.016027450636029242, val_loss: 0.7558014039780684\n",
      "epoch: 10, iter: 54800, train_loss: 0.05735464521683752, val_loss: 0.7060306032372129\n",
      "epoch: 10, iter: 54850, train_loss: 0.05414918666705489, val_loss: 0.713211749864232\n",
      "epoch: 10, iter: 54900, train_loss: 0.043534541819244627, val_loss: 0.7523057197879075\n",
      "epoch: 10, iter: 54950, train_loss: 0.059473690502345564, val_loss: 0.7665631958064\n",
      "epoch: 10, iter: 55000, train_loss: 0.058099535517394545, val_loss: 0.7581765722886772\n",
      "epoch: 10, iter: 55050, train_loss: 0.06948933480307459, val_loss: 0.790030213108488\n",
      "epoch: 10, iter: 55100, train_loss: 0.0781813858821988, val_loss: 0.7433265853839316\n",
      "epoch: 10, iter: 55150, train_loss: 0.08320764979347586, val_loss: 0.7533087453265099\n",
      "epoch: 10, iter: 55200, train_loss: 0.08299532791599631, val_loss: 0.7431839825051605\n",
      "epoch: 10, iter: 55250, train_loss: 0.08329209825024009, val_loss: 0.7924789994195768\n",
      "epoch: 10, iter: 55300, train_loss: 0.07436869917437434, val_loss: 0.7524046224963133\n",
      "epoch: 10, iter: 55350, train_loss: 0.07795798018574715, val_loss: 0.8151760123148086\n",
      "epoch: 10, iter: 55400, train_loss: 0.07659321177750826, val_loss: 0.7939915215703333\n",
      "epoch: 10, iter: 55450, train_loss: 0.08222963064908981, val_loss: 0.7532098522042013\n",
      "epoch: 10, iter: 55500, train_loss: 0.09192845135927201, val_loss: 0.7817356622522804\n",
      "epoch: 11, iter: 55550, train_loss: 0.04042952243238687, val_loss: 0.7742237127890252\n",
      "epoch: 11, iter: 55600, train_loss: 0.049212603997439146, val_loss: 0.8426578359998715\n",
      "epoch: 11, iter: 55650, train_loss: 0.04555158216506243, val_loss: 0.7584428551850045\n",
      "epoch: 11, iter: 55700, train_loss: 0.051702567227184776, val_loss: 0.7894334569098843\n",
      "epoch: 11, iter: 55750, train_loss: 0.04875494112260639, val_loss: 0.7629015164770139\n",
      "epoch: 11, iter: 55800, train_loss: 0.051558300629258154, val_loss: 0.8454335117416018\n",
      "epoch: 11, iter: 55850, train_loss: 0.05957367928698659, val_loss: 0.8027490124960613\n",
      "epoch: 11, iter: 55900, train_loss: 0.06029470594599843, val_loss: 0.80274734726757\n",
      "epoch: 11, iter: 55950, train_loss: 0.05998413539491594, val_loss: 0.8059168473170821\n",
      "epoch: 11, iter: 56000, train_loss: 0.07082037856802344, val_loss: 0.8005470052646224\n",
      "epoch: 11, iter: 56050, train_loss: 0.0726137264445424, val_loss: 0.7429468834855754\n",
      "epoch: 11, iter: 56100, train_loss: 0.0636374083906412, val_loss: 0.7866285296192594\n",
      "epoch: 11, iter: 56150, train_loss: 0.07941747840493918, val_loss: 0.7884769902867117\n",
      "epoch: 11, iter: 56200, train_loss: 0.07956322688609362, val_loss: 0.7924269270745052\n",
      "epoch: 11, iter: 56250, train_loss: 0.07985925702378154, val_loss: 0.7656321908543064\n",
      "epoch: 11, iter: 56300, train_loss: 0.07643879480659961, val_loss: 0.7493199049287541\n",
      "epoch: 12, iter: 56350, train_loss: 0.06451219530776144, val_loss: 0.8017435857824459\n",
      "epoch: 12, iter: 56400, train_loss: 0.05054492447525263, val_loss: 0.8165675747166773\n",
      "epoch: 12, iter: 56450, train_loss: 0.05385292091406882, val_loss: 0.8020273840920941\n",
      "epoch: 12, iter: 56500, train_loss: 0.05728008366189897, val_loss: 0.756381760926763\n",
      "epoch: 12, iter: 56550, train_loss: 0.041818791413679716, val_loss: 0.808287180533075\n",
      "epoch: 12, iter: 56600, train_loss: 0.050602528043091295, val_loss: 0.775346345202938\n",
      "epoch: 12, iter: 56650, train_loss: 0.04470703608356416, val_loss: 0.8281831829601033\n",
      "epoch: 12, iter: 56700, train_loss: 0.05254676876589656, val_loss: 0.7974646344875834\n",
      "epoch: 12, iter: 56750, train_loss: 0.05452789945527911, val_loss: 0.8217598125813114\n",
      "epoch: 12, iter: 56800, train_loss: 0.0663448777794838, val_loss: 0.8146732669727058\n",
      "epoch: 12, iter: 56850, train_loss: 0.06823997464030981, val_loss: 0.7645304988903604\n",
      "epoch: 12, iter: 56900, train_loss: 0.04855122083798051, val_loss: 0.807770446417438\n",
      "epoch: 12, iter: 56950, train_loss: 0.04927627599798143, val_loss: 0.8095929859929784\n",
      "epoch: 12, iter: 57000, train_loss: 0.057450585793703796, val_loss: 0.7958108815987399\n",
      "epoch: 12, iter: 57050, train_loss: 0.07102954331785441, val_loss: 0.8021953101180921\n",
      "epoch: 13, iter: 57100, train_loss: 0.014831133224070071, val_loss: 0.8170182543575384\n",
      "epoch: 13, iter: 57150, train_loss: 0.056656564269214865, val_loss: 0.7877122694329851\n",
      "epoch: 13, iter: 57200, train_loss: 0.038054858073592185, val_loss: 0.7976442966491554\n",
      "epoch: 13, iter: 57250, train_loss: 0.05118127156980336, val_loss: 0.8410677466612713\n",
      "epoch: 13, iter: 57300, train_loss: 0.038563396786339584, val_loss: 0.849071695356612\n",
      "epoch: 13, iter: 57350, train_loss: 0.04486317249480635, val_loss: 0.8324417461445377\n",
      "epoch: 13, iter: 57400, train_loss: 0.04772249724715948, val_loss: 0.8221971664079435\n",
      "epoch: 13, iter: 57450, train_loss: 0.05366696677170694, val_loss: 0.8076895339663621\n",
      "epoch: 13, iter: 57500, train_loss: 0.049245629981160166, val_loss: 0.8450561560642947\n",
      "epoch: 13, iter: 57550, train_loss: 0.05103458266705275, val_loss: 0.7961150515990653\n",
      "epoch: 13, iter: 57600, train_loss: 0.04908481702208519, val_loss: 0.8650750125859193\n",
      "epoch: 13, iter: 57650, train_loss: 0.045944941360503436, val_loss: 0.832191939186898\n",
      "epoch: 13, iter: 57700, train_loss: 0.042871884643100204, val_loss: 0.8533373226405708\n",
      "epoch: 13, iter: 57750, train_loss: 0.05314278651960194, val_loss: 0.8634668696837821\n",
      "epoch: 13, iter: 57800, train_loss: 0.05968250522390008, val_loss: 0.8344750677704051\n",
      "epoch: 13, iter: 57850, train_loss: 0.05292366881854832, val_loss: 0.8452649196242071\n",
      "epoch: 14, iter: 57900, train_loss: 0.06209080424159765, val_loss: 0.9488191636884289\n",
      "epoch: 14, iter: 57950, train_loss: 0.06836078697815537, val_loss: 0.8360701731056165\n",
      "epoch: 14, iter: 58000, train_loss: 0.04611703621223569, val_loss: 0.7709919538847201\n",
      "epoch: 14, iter: 58050, train_loss: 0.034229400111362336, val_loss: 0.8314099426671957\n",
      "epoch: 14, iter: 58100, train_loss: 0.03084263144992292, val_loss: 0.8447405347588716\n",
      "epoch: 14, iter: 58150, train_loss: 0.040938636451028285, val_loss: 0.8564909279915938\n",
      "epoch: 14, iter: 58200, train_loss: 0.03623317727819085, val_loss: 0.809984657604983\n",
      "epoch: 14, iter: 58250, train_loss: 0.03267022757325321, val_loss: 0.837635238933715\n",
      "epoch: 14, iter: 58300, train_loss: 0.03645352563820779, val_loss: 0.8269560249747744\n",
      "epoch: 14, iter: 58350, train_loss: 0.041254512458108364, val_loss: 0.8749386940602284\n",
      "epoch: 14, iter: 58400, train_loss: 0.041423757295124236, val_loss: 0.8414726050416376\n",
      "epoch: 14, iter: 58450, train_loss: 0.05739978963509202, val_loss: 0.9501421580648726\n",
      "epoch: 14, iter: 58500, train_loss: 0.05840568200685084, val_loss: 0.8892294225419403\n",
      "epoch: 14, iter: 58550, train_loss: 0.04974241951480508, val_loss: 0.8753172912795073\n",
      "epoch: 14, iter: 58600, train_loss: 0.05781062559224665, val_loss: 0.8799810371581157\n",
      "epoch: 14, iter: 58650, train_loss: 0.07538588472642005, val_loss: 0.9040374078188732\n",
      "epoch: 15, iter: 58700, train_loss: 0.0760416785813868, val_loss: 0.8819335180862694\n",
      "epoch: 15, iter: 58750, train_loss: 0.0408046767860651, val_loss: 0.8840014044266598\n",
      "epoch: 15, iter: 58800, train_loss: 0.04512379382736981, val_loss: 0.8263775140616545\n",
      "epoch: 15, iter: 58850, train_loss: 0.0334079018374905, val_loss: 0.8532506893774506\n",
      "epoch: 15, iter: 58900, train_loss: 0.034115602793172, val_loss: 0.9245483214688149\n",
      "epoch: 15, iter: 58950, train_loss: 0.04756909827236086, val_loss: 0.887644005524125\n",
      "epoch: 15, iter: 59000, train_loss: 0.049056574180722234, val_loss: 0.8626349860695517\n",
      "epoch: 15, iter: 59050, train_loss: 0.04604989781510085, val_loss: 0.862040112352675\n",
      "epoch: 15, iter: 59100, train_loss: 0.05183332335669547, val_loss: 0.8394575747335034\n",
      "epoch: 15, iter: 59150, train_loss: 0.04351787829771638, val_loss: 0.8300310510928464\n",
      "epoch: 15, iter: 59200, train_loss: 0.02889215759932995, val_loss: 0.879810165447794\n",
      "epoch: 15, iter: 59250, train_loss: 0.04660240396857262, val_loss: 0.8476000401624448\n",
      "epoch: 15, iter: 59300, train_loss: 0.04670234345830977, val_loss: 0.8991001513163754\n",
      "epoch: 15, iter: 59350, train_loss: 0.04933459661900997, val_loss: 0.8428678726124915\n",
      "epoch: 15, iter: 59400, train_loss: 0.03840295581147075, val_loss: 0.8537561593541674\n",
      "epoch: 16, iter: 59450, train_loss: 0.009339884510263801, val_loss: 0.9000485012675546\n",
      "epoch: 16, iter: 59500, train_loss: 0.03472905047237873, val_loss: 0.8911269906979458\n",
      "epoch: 16, iter: 59550, train_loss: 0.027135903872549536, val_loss: 0.8997915426067485\n",
      "epoch: 16, iter: 59600, train_loss: 0.031944579714909195, val_loss: 0.8648977751375004\n",
      "epoch: 16, iter: 59650, train_loss: 0.026173572661355136, val_loss: 0.8755284950232051\n",
      "epoch: 16, iter: 59700, train_loss: 0.030865309224464, val_loss: 0.8527904463231943\n",
      "epoch: 16, iter: 59750, train_loss: 0.03201862228102982, val_loss: 0.8619078292398695\n",
      "epoch: 16, iter: 59800, train_loss: 0.032160410098731516, val_loss: 0.8732381036896615\n",
      "epoch: 16, iter: 59850, train_loss: 0.042174361143261195, val_loss: 0.8673120729482857\n",
      "epoch: 16, iter: 59900, train_loss: 0.035887746608350424, val_loss: 0.8749621614908717\n",
      "epoch: 16, iter: 59950, train_loss: 0.03240535457618535, val_loss: 0.9036294370889664\n",
      "epoch: 16, iter: 60000, train_loss: 0.03794907900970429, val_loss: 0.9896540730052693\n",
      "epoch: 16, iter: 60050, train_loss: 0.04737592292018235, val_loss: 0.9074101182305889\n",
      "epoch: 16, iter: 60100, train_loss: 0.06480419175699353, val_loss: 0.8812089199852792\n",
      "epoch: 16, iter: 60150, train_loss: 0.0504518037289381, val_loss: 0.8674959827950046\n",
      "epoch: 16, iter: 60200, train_loss: 0.05147232002578676, val_loss: 0.9018221197614245\n",
      "epoch: 17, iter: 60250, train_loss: 0.03307108455337584, val_loss: 0.933932015755374\n",
      "epoch: 17, iter: 60300, train_loss: 0.029174183048307895, val_loss: 0.8692455513841787\n",
      "epoch: 17, iter: 60350, train_loss: 0.027146058860234915, val_loss: 0.8367032091708699\n",
      "epoch: 17, iter: 60400, train_loss: 0.030924889855086804, val_loss: 0.9381693757263718\n",
      "epoch: 17, iter: 60450, train_loss: 0.044420844772830606, val_loss: 0.9160505929949937\n",
      "epoch: 17, iter: 60500, train_loss: 0.030312381107360124, val_loss: 0.9004825987633626\n",
      "epoch: 17, iter: 60550, train_loss: 0.03353547706734389, val_loss: 0.915228464611017\n",
      "epoch: 17, iter: 60600, train_loss: 0.027765761921182276, val_loss: 0.8821448289854511\n",
      "epoch: 17, iter: 60650, train_loss: 0.025358796562068166, val_loss: 0.9314168388866315\n",
      "epoch: 17, iter: 60700, train_loss: 0.03056159342173487, val_loss: 0.9491027503446409\n",
      "epoch: 17, iter: 60750, train_loss: 0.03459805984981358, val_loss: 0.866542947045557\n",
      "epoch: 17, iter: 60800, train_loss: 0.0327332862932235, val_loss: 0.90916503728575\n",
      "epoch: 17, iter: 60850, train_loss: 0.042059522550553084, val_loss: 0.9948771409927659\n",
      "epoch: 17, iter: 60900, train_loss: 0.04046507740393281, val_loss: 0.9852776102199676\n",
      "epoch: 17, iter: 60950, train_loss: 0.05316834667697549, val_loss: 0.919292630188784\n",
      "epoch: 18, iter: 61000, train_loss: 0.0034369352320209145, val_loss: 0.9122485534590521\n",
      "epoch: 18, iter: 61050, train_loss: 0.03644725186750293, val_loss: 0.8678031980421892\n",
      "epoch: 18, iter: 61100, train_loss: 0.033777431109920146, val_loss: 0.9433884130921334\n",
      "epoch: 18, iter: 61150, train_loss: 0.033794197426177564, val_loss: 0.9023972408976525\n",
      "epoch: 18, iter: 61200, train_loss: 0.02242050921777263, val_loss: 0.950920685651196\n",
      "epoch: 18, iter: 61250, train_loss: 0.05765523344278336, val_loss: 0.9117743650059791\n",
      "epoch: 18, iter: 61300, train_loss: 0.055882356790825725, val_loss: 0.9250226594080591\n",
      "epoch: 18, iter: 61350, train_loss: 0.04627439878415316, val_loss: 0.8958081555594305\n",
      "epoch: 18, iter: 61400, train_loss: 0.04638064012862742, val_loss: 0.9220059620346993\n",
      "epoch: 18, iter: 61450, train_loss: 0.03926766194868833, val_loss: 0.9059508384033373\n",
      "epoch: 18, iter: 61500, train_loss: 0.030657704076729714, val_loss: 0.8852187952228413\n",
      "epoch: 18, iter: 61550, train_loss: 0.029307063263840975, val_loss: 0.8502668001849181\n",
      "epoch: 18, iter: 61600, train_loss: 0.039561138041317466, val_loss: 0.9271905974597688\n",
      "epoch: 18, iter: 61650, train_loss: 0.032030940218828616, val_loss: 0.9406360121099813\n",
      "epoch: 18, iter: 61700, train_loss: 0.04183493786491454, val_loss: 0.9831137873564556\n",
      "epoch: 18, iter: 61750, train_loss: 0.05401579483412206, val_loss: 0.9039170058669558\n",
      "epoch: 19, iter: 61800, train_loss: 0.012542796982452274, val_loss: 0.9200892357309912\n",
      "epoch: 19, iter: 61850, train_loss: 0.028327323962002993, val_loss: 0.8837527437194898\n",
      "epoch: 19, iter: 61900, train_loss: 0.020694929789751768, val_loss: 0.8937835890776032\n",
      "epoch: 19, iter: 61950, train_loss: 0.018694150377996266, val_loss: 0.930296316078514\n",
      "epoch: 19, iter: 62000, train_loss: 0.0215346661163494, val_loss: 0.951264246444034\n",
      "epoch: 19, iter: 62050, train_loss: 0.02532466223463416, val_loss: 1.0131180350947533\n",
      "epoch: 19, iter: 62100, train_loss: 0.02458238715771586, val_loss: 0.9617260515120378\n",
      "epoch: 19, iter: 62150, train_loss: 0.04290008804760873, val_loss: 0.9319165939358389\n",
      "epoch: 19, iter: 62200, train_loss: 0.032312470725737515, val_loss: 0.9798160341514903\n",
      "epoch: 19, iter: 62250, train_loss: 0.04290727052371949, val_loss: 0.9268563792204402\n",
      "epoch: 19, iter: 62300, train_loss: 0.03260252058506012, val_loss: 0.9301887872112784\n",
      "epoch: 19, iter: 62350, train_loss: 0.02993324092589319, val_loss: 0.948661877186435\n",
      "epoch: 19, iter: 62400, train_loss: 0.03697178551927209, val_loss: 0.9448839122322714\n",
      "epoch: 19, iter: 62450, train_loss: 0.04105447601526976, val_loss: 0.9360988813031251\n",
      "epoch: 19, iter: 62500, train_loss: 0.03399824940599501, val_loss: 0.9133258382226251\n",
      "epoch: 19, iter: 62550, train_loss: 0.043126321835443376, val_loss: 0.9000416272764753\n",
      "epoch: 20, iter: 62600, train_loss: 0.026895373994484544, val_loss: 0.900475242714973\n",
      "epoch: 20, iter: 62650, train_loss: 0.030599858490750195, val_loss: 0.911087676787832\n",
      "epoch: 20, iter: 62700, train_loss: 0.04457114305347204, val_loss: 0.9556749768697532\n",
      "epoch: 20, iter: 62750, train_loss: 0.0454751065466553, val_loss: 0.9413419455100017\n",
      "epoch: 20, iter: 62800, train_loss: 0.031001841351389885, val_loss: 0.9312280921419714\n",
      "epoch: 20, iter: 62850, train_loss: 0.025512947831302882, val_loss: 0.96982224921512\n",
      "epoch: 20, iter: 62900, train_loss: 0.02405018489342183, val_loss: 0.9469653064278281\n",
      "epoch: 20, iter: 62950, train_loss: 0.040968575943261386, val_loss: 0.9220960574924566\n",
      "epoch: 20, iter: 63000, train_loss: 0.03050246470142156, val_loss: 0.9783191151300054\n",
      "epoch: 20, iter: 63050, train_loss: 0.0360940298717469, val_loss: 0.988257469455148\n",
      "epoch: 20, iter: 63100, train_loss: 0.04929319355171174, val_loss: 0.9076313306191924\n",
      "epoch: 20, iter: 63150, train_loss: 0.036205982360988855, val_loss: 0.9372711870700691\n",
      "epoch: 20, iter: 63200, train_loss: 0.028979273126460613, val_loss: 0.9268574951940282\n",
      "epoch: 20, iter: 63250, train_loss: 0.03802720068953931, val_loss: 0.9566060283761115\n",
      "epoch: 20, iter: 63300, train_loss: 0.04470615153666586, val_loss: 0.9121190681579007\n",
      "epoch: 21, iter: 63350, train_loss: 0.00843523332849145, val_loss: 0.9003143589587728\n",
      "epoch: 21, iter: 63400, train_loss: 0.029648184315301477, val_loss: 0.8997685738429901\n",
      "epoch: 21, iter: 63450, train_loss: 0.02717626534868032, val_loss: 0.8911642529022922\n",
      "epoch: 21, iter: 63500, train_loss: 0.017709488186519594, val_loss: 0.9067211900926699\n",
      "epoch: 21, iter: 63550, train_loss: 0.012146441040094942, val_loss: 0.9146710217568526\n",
      "epoch: 21, iter: 63600, train_loss: 0.015819738656282424, val_loss: 0.9190427484406027\n",
      "epoch: 21, iter: 63650, train_loss: 0.026220728764310478, val_loss: 0.9317507065215688\n",
      "epoch: 21, iter: 63700, train_loss: 0.027635013344697656, val_loss: 0.9458594333594013\n",
      "epoch: 21, iter: 63750, train_loss: 0.033383952579461036, val_loss: 0.8709789138690681\n",
      "epoch: 21, iter: 63800, train_loss: 0.026735345462802797, val_loss: 0.9251290347166122\n",
      "epoch: 21, iter: 63850, train_loss: 0.03363187063485384, val_loss: 1.018709775179055\n",
      "epoch: 21, iter: 63900, train_loss: 0.031026703068055213, val_loss: 0.9470288679478275\n",
      "epoch: 21, iter: 63950, train_loss: 0.025477260663174094, val_loss: 0.95525557742377\n",
      "epoch: 21, iter: 64000, train_loss: 0.03931109477765858, val_loss: 0.942732442526301\n",
      "epoch: 21, iter: 64050, train_loss: 0.04758359569590539, val_loss: 0.8934301517571613\n",
      "epoch: 21, iter: 64100, train_loss: 0.0344784657144919, val_loss: 0.8882956349166335\n",
      "epoch: 22, iter: 64150, train_loss: 0.014140511034056544, val_loss: 0.8890475087864383\n",
      "epoch: 22, iter: 64200, train_loss: 0.0162744894111529, val_loss: 0.9632727325342263\n",
      "epoch: 22, iter: 64250, train_loss: 0.016100611088331787, val_loss: 0.9470579062297846\n",
      "epoch: 22, iter: 64300, train_loss: 0.01995796732371673, val_loss: 1.0145054522213663\n",
      "epoch: 22, iter: 64350, train_loss: 0.03259505504276603, val_loss: 0.9465547583665058\n",
      "epoch: 22, iter: 64400, train_loss: 0.020200135393533856, val_loss: 0.9402373328710057\n",
      "epoch: 22, iter: 64450, train_loss: 0.024213485694490375, val_loss: 0.9106008163682974\n",
      "epoch: 22, iter: 64500, train_loss: 0.025038851876743137, val_loss: 0.9552927096937872\n",
      "epoch: 22, iter: 64550, train_loss: 0.033387850117869676, val_loss: 0.9440887038874778\n",
      "epoch: 22, iter: 64600, train_loss: 0.03358346078544855, val_loss: 0.9799464557580887\n",
      "epoch: 22, iter: 64650, train_loss: 0.03717252396047115, val_loss: 0.9394069173533446\n",
      "epoch: 22, iter: 64700, train_loss: 0.031508350991643966, val_loss: 0.946369610964113\n",
      "epoch: 22, iter: 64750, train_loss: 0.05190242039971053, val_loss: 1.0799036344904809\n",
      "epoch: 22, iter: 64800, train_loss: 0.04653831242118031, val_loss: 0.9604074996747788\n",
      "epoch: 22, iter: 64850, train_loss: 0.04113888537976891, val_loss: 0.9594105974693966\n",
      "epoch: 22, iter: 64900, train_loss: 0.036922913193702694, val_loss: 0.8863073426067449\n",
      "epoch: 23, iter: 64950, train_loss: 0.019264053909573704, val_loss: 0.9419764954193383\n",
      "epoch: 23, iter: 65000, train_loss: 0.023429321092553437, val_loss: 0.9080483063011412\n",
      "epoch: 23, iter: 65050, train_loss: 0.02028065430931747, val_loss: 0.894104970203843\n",
      "epoch: 23, iter: 65100, train_loss: 0.019072781447321177, val_loss: 0.898677291099433\n",
      "epoch: 23, iter: 65150, train_loss: 0.015553993061184884, val_loss: 0.9412500577367795\n",
      "epoch: 23, iter: 65200, train_loss: 0.029183678175322712, val_loss: 0.916095986582671\n",
      "epoch: 23, iter: 65250, train_loss: 0.021350187975913287, val_loss: 0.9482591841251228\n",
      "epoch: 23, iter: 65300, train_loss: 0.021319597056135536, val_loss: 0.9438090345282464\n",
      "epoch: 23, iter: 65350, train_loss: 0.030228871367871762, val_loss: 0.8976561637820711\n",
      "epoch: 23, iter: 65400, train_loss: 0.02864630822557956, val_loss: 0.9180600491298991\n",
      "epoch: 23, iter: 65450, train_loss: 0.02993611471261829, val_loss: 0.9021385114663726\n",
      "epoch: 23, iter: 65500, train_loss: 0.03007882903330028, val_loss: 0.9623099373784035\n",
      "epoch: 23, iter: 65550, train_loss: 0.04696867010556161, val_loss: 1.0675591680274648\n",
      "epoch: 23, iter: 65600, train_loss: 0.03846294643357396, val_loss: 0.980442450684347\n",
      "epoch: 23, iter: 65650, train_loss: 0.04362223330885172, val_loss: 0.9941436151030717\n",
      "epoch: 24, iter: 65700, train_loss: 0.004447461157105863, val_loss: 0.8925719187138187\n",
      "epoch: 24, iter: 65750, train_loss: 0.020062050633132458, val_loss: 0.9335968617800694\n",
      "epoch: 24, iter: 65800, train_loss: 0.013317923811264336, val_loss: 0.9531296577043594\n",
      "epoch: 24, iter: 65850, train_loss: 0.022897700620815156, val_loss: 0.9695975560291558\n",
      "epoch: 24, iter: 65900, train_loss: 0.018449588441289962, val_loss: 1.0069008875804342\n",
      "epoch: 24, iter: 65950, train_loss: 0.017907161768525838, val_loss: 0.9686175146300322\n",
      "epoch: 24, iter: 66000, train_loss: 0.018657170911319555, val_loss: 0.9786247977405597\n",
      "epoch: 24, iter: 66050, train_loss: 0.026379190883599222, val_loss: 0.9819164152737636\n",
      "epoch: 24, iter: 66100, train_loss: 0.024337541200220584, val_loss: 0.9840707860554859\n",
      "epoch: 24, iter: 66150, train_loss: 0.024562273498158902, val_loss: 1.0543791862430087\n",
      "epoch: 24, iter: 66200, train_loss: 0.030035882191732526, val_loss: 1.0210106585435808\n",
      "epoch: 24, iter: 66250, train_loss: 0.041394617035984994, val_loss: 0.8952054884403374\n",
      "epoch: 24, iter: 66300, train_loss: 0.02224101236090064, val_loss: 0.9693500424266621\n",
      "epoch: 24, iter: 66350, train_loss: 0.03601100945845246, val_loss: 0.9800033664247793\n",
      "epoch: 24, iter: 66400, train_loss: 0.033974822293967005, val_loss: 0.9456568140133171\n",
      "epoch: 24, iter: 66450, train_loss: 0.03151634924579412, val_loss: 1.0231117044284845\n",
      "epoch: 25, iter: 66500, train_loss: 0.023144585080444813, val_loss: 0.9575722373215256\n",
      "epoch: 25, iter: 66550, train_loss: 0.021500880285166203, val_loss: 0.9624080175806762\n",
      "epoch: 25, iter: 66600, train_loss: 0.02706210405100137, val_loss: 0.9737957803307066\n",
      "epoch: 25, iter: 66650, train_loss: 0.021169062084518374, val_loss: 0.9430123478364033\n",
      "epoch: 25, iter: 66700, train_loss: 0.02995380082167685, val_loss: 0.9418469414969158\n",
      "epoch: 25, iter: 66750, train_loss: 0.01960956513416022, val_loss: 0.9204014475178567\n",
      "epoch: 25, iter: 66800, train_loss: 0.020641163771506398, val_loss: 0.9897640315210743\n",
      "epoch: 25, iter: 66850, train_loss: 0.03253856070805341, val_loss: 0.9813482307704391\n",
      "epoch: 25, iter: 66900, train_loss: 0.027713201316073535, val_loss: 0.9553660011974869\n",
      "epoch: 25, iter: 66950, train_loss: 0.019916051495820285, val_loss: 0.9593782865317764\n",
      "epoch: 25, iter: 67000, train_loss: 0.017912248657085003, val_loss: 0.99117738103411\n",
      "epoch: 25, iter: 67050, train_loss: 0.0207868045498617, val_loss: 0.9433447813532155\n",
      "epoch: 25, iter: 67100, train_loss: 0.018552708001807333, val_loss: 0.9806722121633542\n",
      "epoch: 25, iter: 67150, train_loss: 0.02945481502916664, val_loss: 1.0160849745486193\n",
      "epoch: 25, iter: 67200, train_loss: 0.025679511963389814, val_loss: 1.064076273684289\n",
      "epoch: 25, iter: 67250, train_loss: 0.04012391958851367, val_loss: 1.0252208836898682\n",
      "epoch: 26, iter: 67300, train_loss: 0.02780342602869496, val_loss: 0.9998195130544104\n",
      "epoch: 26, iter: 67350, train_loss: 0.021811432524118574, val_loss: 0.987420116165641\n",
      "epoch: 26, iter: 67400, train_loss: 0.02020942298695445, val_loss: 0.9991711555582703\n",
      "epoch: 26, iter: 67450, train_loss: 0.018295439628418536, val_loss: 1.0304733471126313\n",
      "epoch: 26, iter: 67500, train_loss: 0.029809040329419077, val_loss: 0.9714136673196866\n",
      "epoch: 26, iter: 67550, train_loss: 0.013632077181246132, val_loss: 0.9538426268252598\n",
      "epoch: 26, iter: 67600, train_loss: 0.024137682504951952, val_loss: 0.9704365942888199\n",
      "epoch: 26, iter: 67650, train_loss: 0.023056351442355662, val_loss: 0.9303853570655652\n",
      "epoch: 26, iter: 67700, train_loss: 0.02888334251474589, val_loss: 0.9369139037314494\n",
      "epoch: 26, iter: 67750, train_loss: 0.025679361436050385, val_loss: 0.9772888302423393\n",
      "epoch: 26, iter: 67800, train_loss: 0.029405860195402055, val_loss: 0.962300645318001\n",
      "epoch: 26, iter: 67850, train_loss: 0.028943882766179742, val_loss: 1.1916582908979647\n",
      "epoch: 26, iter: 67900, train_loss: 0.061344933840446175, val_loss: 1.017032095011632\n",
      "epoch: 26, iter: 67950, train_loss: 0.04034337201155722, val_loss: 0.9927509797226851\n",
      "epoch: 26, iter: 68000, train_loss: 0.03633939824067056, val_loss: 0.9561050043554064\n",
      "epoch: 27, iter: 68050, train_loss: 0.011170414104126393, val_loss: 1.0239624403844214\n",
      "epoch: 27, iter: 68100, train_loss: 0.03021261977730319, val_loss: 1.0511490732051765\n",
      "epoch: 27, iter: 68150, train_loss: 0.02683576688170433, val_loss: 1.0070048532668192\n",
      "epoch: 27, iter: 68200, train_loss: 0.03084993935190141, val_loss: 0.9452748982010374\n",
      "epoch: 27, iter: 68250, train_loss: 0.02703722834587097, val_loss: 0.9446550452025833\n",
      "epoch: 27, iter: 68300, train_loss: 0.021743241895455866, val_loss: 0.9521413547977521\n",
      "epoch: 27, iter: 68350, train_loss: 0.021442397844512014, val_loss: 0.9616587580579101\n",
      "epoch: 27, iter: 68400, train_loss: 0.022667048203293235, val_loss: 0.9838284443897806\n",
      "epoch: 27, iter: 68450, train_loss: 0.02536640013102442, val_loss: 0.9843889059154851\n",
      "epoch: 27, iter: 68500, train_loss: 0.025779269519262016, val_loss: 0.9237373957208767\n",
      "epoch: 27, iter: 68550, train_loss: 0.01608376292511821, val_loss: 0.9529802254430807\n",
      "epoch: 27, iter: 68600, train_loss: 0.016384797433856874, val_loss: 0.9752425605514247\n",
      "epoch: 27, iter: 68650, train_loss: 0.018105727997608484, val_loss: 0.962816477059179\n",
      "epoch: 27, iter: 68700, train_loss: 0.020998715017922224, val_loss: 1.0473380302357826\n",
      "epoch: 27, iter: 68750, train_loss: 0.02954603769350797, val_loss: 1.0000802258587187\n",
      "epoch: 27, iter: 68800, train_loss: 0.025609160219319166, val_loss: 0.9801552868952417\n",
      "epoch: 28, iter: 68850, train_loss: 0.016011930285021663, val_loss: 0.9819391525475083\n",
      "epoch: 28, iter: 68900, train_loss: 0.01796975127886981, val_loss: 0.9737707758025759\n",
      "epoch: 28, iter: 68950, train_loss: 0.025036045382730663, val_loss: 0.9799007469681418\n",
      "epoch: 28, iter: 69000, train_loss: 0.021140072436537594, val_loss: 0.974796057127084\n",
      "epoch: 28, iter: 69050, train_loss: 0.017796876067295672, val_loss: 1.0200820787317435\n",
      "epoch: 28, iter: 69100, train_loss: 0.026367770796641706, val_loss: 0.9653917380199311\n",
      "epoch: 28, iter: 69150, train_loss: 0.017042349223047495, val_loss: 0.9727691248723656\n",
      "epoch: 28, iter: 69200, train_loss: 0.013006689813919366, val_loss: 0.946852591956497\n",
      "epoch: 28, iter: 69250, train_loss: 0.019286262742243706, val_loss: 0.9764562718048218\n",
      "epoch: 28, iter: 69300, train_loss: 0.0319769507390447, val_loss: 0.9581999225411445\n",
      "epoch: 28, iter: 69350, train_loss: 0.019785311659798025, val_loss: 0.9623431736116956\n",
      "epoch: 28, iter: 69400, train_loss: 0.026356816799379887, val_loss: 0.9786263626472206\n",
      "epoch: 28, iter: 69450, train_loss: 0.032011640425771475, val_loss: 0.98878848457792\n",
      "epoch: 28, iter: 69500, train_loss: 0.031863163504749534, val_loss: 0.9830216636323625\n",
      "epoch: 28, iter: 69550, train_loss: 0.038850088259205225, val_loss: 0.9483322475556355\n",
      "epoch: 29, iter: 69600, train_loss: 0.0008120983466506004, val_loss: 0.9574299533465865\n",
      "epoch: 29, iter: 69650, train_loss: 0.02170352067798376, val_loss: 0.9499947728624769\n",
      "epoch: 29, iter: 69700, train_loss: 0.023448960368987172, val_loss: 1.01854271617285\n",
      "epoch: 29, iter: 69750, train_loss: 0.01818345222854987, val_loss: 1.0182830486327978\n",
      "epoch: 29, iter: 69800, train_loss: 0.026635073581710456, val_loss: 1.0252623015148625\n",
      "epoch: 29, iter: 69850, train_loss: 0.02260736171156168, val_loss: 0.9780763275684066\n",
      "epoch: 29, iter: 69900, train_loss: 0.01589545178692788, val_loss: 1.0111002523428316\n",
      "epoch: 29, iter: 69950, train_loss: 0.01832990732509643, val_loss: 0.9798571277575888\n",
      "epoch: 29, iter: 70000, train_loss: 0.01854658910539001, val_loss: 1.086083965696347\n",
      "epoch: 29, iter: 70050, train_loss: 0.03416224277578294, val_loss: 1.0161947256820216\n",
      "epoch: 29, iter: 70100, train_loss: 0.04467978802509606, val_loss: 1.0650417294092238\n",
      "epoch: 29, iter: 70150, train_loss: 0.03241686314344406, val_loss: 0.962279228647803\n",
      "epoch: 29, iter: 70200, train_loss: 0.020508801341056825, val_loss: 0.9572193078744183\n",
      "epoch: 29, iter: 70250, train_loss: 0.024842977644875645, val_loss: 0.9540649097246728\n",
      "epoch: 29, iter: 70300, train_loss: 0.015908075096085668, val_loss: 1.0072892955534019\n",
      "epoch: 29, iter: 70350, train_loss: 0.025472231097519397, val_loss: 0.9411176793324719\n",
      "best loss:  0.5628298413791474\n",
      "Born Again...\n",
      "Gen:  0 , best loss:  0.5481929880608419\n",
      "Gen:  1 , best loss:  0.5344467559817491\n",
      "Gen:  2 , best loss:  0.5628298413791474\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset cifar10 --out ./snapshots --n_epoch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8140a4-27f7-486f-9192-9855bbdd28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "#from logger import SummaryLogger\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#import utils\n",
    "from ban.models.resnet import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa4adb5-e27f-4aba-a664-731b253dc06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='born again for CIFAR10')\n",
    "parser.add_argument('--text', default='log.txt', type=str)\n",
    "parser.add_argument('--load_pretrained_teacher', default='./trained/teacher-res50-cifar10.pth', type=str)\n",
    "parser.add_argument('--exp_name', default='cifar10/stu_res34', type=str)\n",
    "parser.add_argument('--log_time', default='1', type=str)\n",
    "parser.add_argument('--lr', default='0.1', type=float)\n",
    "parser.add_argument('--resume_epoch', default='0', type=int)\n",
    "parser.add_argument('--epoch', default='163', type=int)\n",
    "parser.add_argument('--n_gen', default='5', type=int) #决定generation的次数\n",
    "#parser.add_argument('--n_models', default=[''], type=list)\n",
    "parser.add_argument('--decay_epoch', default=[82, 123], nargs=\"*\", type=int)\n",
    "parser.add_argument('--w_decay', default='5e-4', type=float)\n",
    "parser.add_argument('--cu_num', default='0', type=str)\n",
    "parser.add_argument('--seed', default='1', type=str)\n",
    "parser.add_argument('--load_pretrained', default='  ', type=str)\n",
    "parser.add_argument('--save_model', default='ckpt.t7', type=str)\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494dcfd7-e8be-41c7-b305-572c7137306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#### random Seed #####\n",
    "num = random.randint(1, 10000)\n",
    "random.seed(num)\n",
    "torch.manual_seed(num)\n",
    "#####################\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.cu_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb8b015-a3ee-4b4b-8eed-9b4765259ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Data loader\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7a89a9-c3d2-4e84-9217-3b7c294581ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resnet8_cifar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_215672/3928452126.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mW_DECAY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbase_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet8_cifar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_tea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resnet8_cifar' is not defined"
     ]
    }
   ],
   "source": [
    "#Other parameters\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "RESUME_EPOCH = args.resume_epoch\n",
    "DECAY_EPOCH = args.decay_epoch\n",
    "DECAY_EPOCH = [ep - RESUME_EPOCH for ep in DECAY_EPOCH]\n",
    "FINAL_EPOCH = args.epoch\n",
    "EXPERIMENT_NAME = args.exp_name\n",
    "W_DECAY = args.w_decay\n",
    "base_lr = args.lr\n",
    "\n",
    "# Model\n",
    "model_tea = ResNet50()\n",
    "#print(model_tea)\n",
    "model_tea.to(DEVICE)\n",
    "\n",
    "#导入模型\n",
    "path = args.load_pretrained_teacher\n",
    "model_tea.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e4024e-01f7-41ea-8728-c2263471c7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval(net):\n",
    "    loader = testloader\n",
    "    flag = 'Test'\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "    net.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "\n",
    "    total = 0\n",
    "    criterion_CE = nn.CrossEntropyLoss()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        outputs= net(inputs)\n",
    "\n",
    "\n",
    "        loss = criterion_CE(outputs, targets)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.detach(), 1)\n",
    "\n",
    "\n",
    "        total += targets.size(0)\n",
    "\n",
    "        correct += predicted.eq(targets.detach()).cpu().sum().float().item()\n",
    "        b_idx = batch_idx\n",
    "\n",
    "    print('%s \\t Time Taken: %.2f sec' % (flag, time.time() - epoch_start_time))\n",
    "    print('Loss: %.3f | Acc net: %.3f%%' % (train_loss / (b_idx + 1), 100. * correct / total))\n",
    "    return val_loss / (b_idx + 1),  correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711419c9-72dc-444d-bcbd-6ef1ace1f151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distillation(outputs_stu, labels, outputs_tea, temp, alpha):\n",
    "    #y: 学生预测的概率分布\n",
    "    #labels: 实际标签\n",
    "    #teacher_scores: 老师预测的概率分布\n",
    "    #temp: 温度系数\n",
    "    #alpha: 损失调整因子\n",
    "    criterion = nn.KLDivLoss()\n",
    "    outputs_S = F.log_softmax(outputs_stu/temp, dim=1) #dim指的是归一化的方式，如果为0是对列做归一化，1是对行做归一化\n",
    "    outputs_T = F.softmax(outputs_tea/temp, dim=1)\n",
    "    loss = criterion(outputs_S, outputs_T) * temp * temp * 2.0 * alpha\n",
    "    \n",
    "    final_loss = F.cross_entropy(outputs_stu, labels) * (1 - alpha) + loss * alpha \n",
    "    return final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f40225e7-7c6c-4d80-b2b7-1b49c4abfca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model_stu, epoch, model_tea):\n",
    "    epoch_start_time = time.time()\n",
    "    print('\\n EPOCH: %d' % epoch)\n",
    "    model_stu.train()\n",
    "    model_tea.eval()\n",
    "    \n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    global optimizer  \n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs_tea = model_tea(inputs)\n",
    "        outputs_stu = model_stu(inputs)\n",
    "        \n",
    "        # 计算误差\n",
    "        loss = distillation(outputs_stu, targets, outputs_tea, temp=5., alpha=0.7)#alpha=.7\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()  #loss都直接用loss表示的，结果就是每次迭代，空间占用就会增加，直到cpu或者gup爆炸。解决办法：把除了loss.backward()之外的loss调用都改成loss.item()，就可以解决。\n",
    "        \n",
    "        _, predicted = torch.max(outputs_stu.detach(), 1)\n",
    "        total += targets.size(0)\n",
    "\n",
    "        correct += predicted.eq(targets.detach()).cpu().sum().float().item()\n",
    "\n",
    "\n",
    "        b_idx = batch_idx\n",
    "\n",
    "    print('Train s1 \\t Time Taken: %.2f sec' % (time.time() - epoch_start_time))\n",
    "    print('Loss: %.3f | Acc net: %.3f%%|' % (train_loss / (b_idx + 1), 100. * correct / total))\n",
    "    return train_loss / (b_idx + 1), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd091e7d-2a8c-49c2-b6d8-05cc621a9d55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_log = datetime.now().strftime('%m-%d %H:%M')\n",
    "if int(args.log_time) :\n",
    "    folder_name = 'teacher_{}'.format(time_log)\n",
    "path = os.path.join(EXPERIMENT_NAME, folder_name)\n",
    "\n",
    "if not os.path.exists('born-again/' + path):\n",
    "    os.makedirs('born-again/' + path)\n",
    "if not os.path.exists('logs/' + path):\n",
    "    os.makedirs('logs/' + path)\n",
    "\n",
    "# Save argparse arguments as logging\n",
    "with open('logs/{}/commandline_args.txt'.format(path), 'w') as f:\n",
    "    json.dump(args.__dict__, f, indent=2)\n",
    "\n",
    "# Instantiate logger\n",
    "#logger = SummaryLogger(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a514c714-00f8-4966-ba53-463c84b53cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the 3-th generation\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_195802/1990663402.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m### Train ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_stu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_tea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = './born-again/cifar10/stu_res34/gen2/Model_149.pth'\n",
    "#best_model1 = './born-again/cifar10/stu_res34/gen0/Model_159.pth'\n",
    "#best_model2 = './born-again/cifar10/stu_res34/gen1/Model_161.pth' #需要不停置换\n",
    "for gen in range(3,5):\n",
    "    best_acc = 0 #这里每个gen都要更新一次\n",
    "    \n",
    "    print(\"This is the {}-th generation\".format(gen))\n",
    "    model_stu = ResNet34()\n",
    "    model_stu.to(DEVICE)\n",
    "\n",
    "    if gen >= 1:\n",
    "        model_tea = ResNet34()\n",
    "        model_tea.to(DEVICE)\n",
    "        model_tea.load_state_dict(torch.load(best_model))\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    optimizer = optim.SGD(model_stu.parameters(), lr=base_lr, momentum=0.9, weight_decay=W_DECAY)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=DECAY_EPOCH, gamma=0.1)\n",
    "    criterion_CE = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(RESUME_EPOCH, FINAL_EPOCH+1):\n",
    "        f = open(os.path.join(\"./born-again/cifar10\", 'log.txt'), \"a\")\n",
    "\n",
    "        ### Train ###\n",
    "        \n",
    "        train_loss, acc = train(model_stu, epoch, model_tea)\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        ### Evaluate  ###\n",
    "        val_loss, test_acc  = eval(model_stu)\n",
    "        if best_acc < test_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model_stu.state_dict(), './born-again/cifar10/stu_res34/gen{}/Model_{}.pth'.format(gen, epoch))\n",
    "            \n",
    "            best_model = './born-again/cifar10/stu_res34/gen{}/Model_{}.pth'.format(gen, epoch)\n",
    "            print(\"best_model:\", best_model)\n",
    "\n",
    "        f.write('EPOCH {epoch} \\t'\n",
    "                'ACC_net : {acc_net:.4f} \\t  \\n'.format(epoch=epoch, acc_net=test_acc)\n",
    "                )\n",
    "        f.close()\n",
    "\n",
    "\"\"\"\n",
    "utils.save_checkpoint({\n",
    "    'epoch': epoch,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "}, True, 'ckpt/' + path, filename='Model_{}.pth'.format(epoch))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3076f59d-e889-4ab8-83f4-62595c6092b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test \t Time Taken: 7.91 sec\n",
      "Loss: 0.010 | Acc net: 96.210%\n"
     ]
    }
   ],
   "source": [
    "def load_checkpoint(model, checkpoint):\n",
    "    m_keys = list(model.state_dict().keys())\n",
    "\n",
    "    if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "        c_keys = list(checkpoint['state_dict'].keys())\n",
    "        not_m_keys = [i for i in c_keys if i not in m_keys]\n",
    "        not_c_keys = [i for i in m_keys if i not in c_keys]\n",
    "        model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n",
    "    else:\n",
    "        c_keys = list(checkpoint.keys())\n",
    "        not_m_keys = [i for i in c_keys if i not in m_keys]\n",
    "        not_c_keys = [i for i in m_keys if i not in c_keys]\n",
    "        model.load_state_dict(checkpoint, strict=False)\n",
    "        \n",
    "def eval_multi(net1, net2, net3, net4):\n",
    "    loader = testloader\n",
    "    flag = 'Test'\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "    net1.eval()\n",
    "    net2.eval()\n",
    "    net3.eval()\n",
    "    '''\n",
    "   \n",
    "    \n",
    "    net4.eval()\n",
    "    \n",
    "    net5.eval()\n",
    "\n",
    "    '''\n",
    "    val_loss = 0\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "\n",
    "    total = 0\n",
    "    criterion_CE = nn.CrossEntropyLoss()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        outputs1= net1(inputs)\n",
    "        outputs2= net2(inputs)\n",
    "        outputs3= net3(inputs)\n",
    "        outputs4= net4(inputs)\n",
    "        '''    \n",
    "        \n",
    "        \n",
    "         \n",
    "        \n",
    "        outputs5= net5(inputs)\n",
    "\n",
    "        '''\n",
    "\n",
    "        #outputs = (outputs1  + outputs2 + outputs3 + outputs4 + outputs5) / 5\n",
    "        outputs = (outputs1 + outputs2 + outputs3 + outputs4 ) /4\n",
    "        loss = criterion_CE(outputs, targets)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.detach(), 1)\n",
    "\n",
    "\n",
    "        total += targets.size(0)\n",
    "\n",
    "        correct += predicted.eq(targets.detach()).cpu().sum().float().item()\n",
    "        b_idx = batch_idx\n",
    "\n",
    "    print('%s \\t Time Taken: %.2f sec' % (flag, time.time() - epoch_start_time))\n",
    "    #print('Loss: %.3f | Acc net: %.3f%%' % (train_loss / (b_idx + 1), 100. * correct / total))\n",
    "    print('Loss: %.3f | Acc net: %.3f%%' % (1 / (b_idx + 1), 100. * correct / total))\n",
    "    return val_loss / (b_idx + 1),  correct / total\n",
    "model1 = ResNet34()\n",
    "model2 = ResNet34()\n",
    "model3 = ResNet34()\n",
    "model4 = ResNet34()\n",
    "model5 = ResNet34()\n",
    "\n",
    "state1 = torch.load('./born-again/cifar10/stu_res34/1/gen0/Model_150.pth')\n",
    "state2 = torch.load('./born-again/cifar10/stu_res34/1/gen1/Model_196.pth')\n",
    "state3 = torch.load('./born-again/cifar10/stu_res34/1/gen2/Model_152.pth')\n",
    "state4 = torch.load('./born-again/cifar10/stu_res34/1/gen3/Model_154.pth')\n",
    "state5 = torch.load('./born-again/cifar10/stu_res34/1/gen4/Model_145.pth')\n",
    "#state6 = torch.load('./born-again/cifar10/stu_res34/gen0-3/gen0/Model_159.pth')\n",
    "#state7 = torch.load('./born-again/cifar10/stu_res34/gen0-3/gen1/Model_161.pth')\n",
    "#state8 = torch.load('./born-again/cifar10/stu_res34/gen0-3/gen2/Model_162.pth')\n",
    "load_checkpoint(model1, state1)\n",
    "load_checkpoint(model2, state2)\n",
    "load_checkpoint(model3, state3)\n",
    "load_checkpoint(model4, state4)\n",
    "load_checkpoint(model5, state5)\n",
    "#load_checkpoint(model6, state6)\n",
    "#load_checkpoint(model7, state7)\n",
    "#load_checkpoint(model8, state8)\n",
    "model1.to(DEVICE)\n",
    "model2.to(DEVICE)\n",
    "model3.to(DEVICE)\n",
    "model4.to(DEVICE)\n",
    "model5.to(DEVICE)\n",
    "#model6.to(DEVICE)\n",
    "#model7.to(DEVICE)\n",
    "#model8.to(DEVICE)\n",
    "\n",
    "val_loss, test_acc  = eval_multi(model2, model5, model1, model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b990ef17-a7a8-4973-9280-89f13a442e01",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfb95288-6d9a-40cf-a286-70434c92df1e",
   "metadata": {},
   "source": [
    "Test \t Time Taken: 3.50 sec\n",
    "Loss: 0.000 | Acc net: 95.350%\n",
    "Test \t Time Taken: 3.51 sec\n",
    "Loss: 0.000 | Acc net: 95.520%\n",
    "Test \t Time Taken: 3.58 sec\n",
    "Loss: 0.000 | Acc net: 95.420%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.9-cuda11-wushangrui (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
